{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRIiLcyy_u4z",
        "outputId": "d6c6cbce-0f79-4886-dc5c-1c3c59cae8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfygxmPZEiAy"
      },
      "source": [
        "###Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-YfrFFVB7ZV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import codecs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, LSTM, Bidirectional\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkd7jPpcElRP"
      },
      "source": [
        "###Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuYeoi-CCAlc"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/Chatbot LSTM/kamusdata.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Q5P1GV8XVK"
      },
      "source": [
        "###Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1YN6huBlQJu",
        "outputId": "76bfe152-53f9-44dd-d9dc-0de0150ff1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pertanyaan Bersih: ['halo', 'hai', 'selamat pagi', 'assalamualaikum', 'selamat pagi']\n",
            "Jawaban Bersih: ['<START> halo! apa yang bisa saya bantu? <END>', '<START> hai, kamu butuh bantuan apa? <END>', '<START> selamat pagi! apa yang bisa saya lakukan untuk anda? <END>', '<START> waalaikumsalam <END>', '<START> halo! ini adalah chatbot informasi seminar-fst <END>']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')  # Unduh corpus WordNet untuk lemmatisasi (lakukan sekali saat pertama kali)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def get_all_conversations(path):\n",
        "    all_conversations = []\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            # Pisahkan pertanyaan dan jawaban menggunakan tanda koma\n",
        "            question, answer = line.strip().split('\\t')\n",
        "            all_conversations.append((question, answer))\n",
        "    return all_conversations\n",
        "\n",
        "def clean_text(text_to_clean):\n",
        "    text = text_to_clean.lower()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "    cleaned_text = ' '.join(lemmatized_words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def get_clean_q_and_a(conversations):\n",
        "    ctx_and_target = []\n",
        "    for question, answer in conversations:\n",
        "        # Bersihkan pertanyaan dan jawaban serta tambahkan token <START> dan <END>\n",
        "        cleaned_question = clean_text(question)\n",
        "        cleaned_answer = '<START> ' + clean_text(answer) + ' <END>'\n",
        "        ctx_and_target.append((cleaned_question, cleaned_answer))\n",
        "    # zip dengan * operator untuk memisahkan pertanyaan dan jawaban\n",
        "    context, target = zip(*ctx_and_target)\n",
        "    return list(context), list(target)\n",
        "\n",
        "# Path ke file dataset\n",
        "path = '/content/drive/My Drive/Chatbot LSTM/kamusdata.txt'\n",
        "\n",
        "# Dapatkan semua percakapan dari file\n",
        "all_conversations = get_all_conversations(path)\n",
        "\n",
        "# Bersihkan pertanyaan dan jawaban serta tambahkan token <START> dan <END>\n",
        "cleaned_questions, cleaned_answers = get_clean_q_and_a(all_conversations)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"Pertanyaan Bersih:\", cleaned_questions[:5])\n",
        "print(\"Jawaban Bersih:\", cleaned_answers[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n0o8Ed8B7sv"
      },
      "source": [
        "###Random Shuffle pada Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWA3xTLmBg3y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pengacakan pertanyaan dan jawaban\n",
        "combined_data = list(zip(cleaned_questions, cleaned_answers))\n",
        "random.shuffle(combined_data)\n",
        "\n",
        "# Pisahkan kembali data yang telah diacak\n",
        "shuffled_questions, shuffled_answers = zip(*combined_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNvZOQPwBvxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc007cf4-d7ee-4542-c0c8-d52fdb4373a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Pertanyaan Sebelum Pengacakan:\n",
            "halo\n",
            "hai\n",
            "selamat pagi\n",
            "assalamualaikum\n",
            "selamat pagi\n",
            "pagi\n",
            "selamat siang\n",
            "selamat siang\n",
            "siang\n",
            "selamat malam\n",
            "malam\n",
            "selamat sore\n",
            "sore\n",
            "hai, apa kabar?\n",
            "kabar saya baik\n",
            "apakah anda merasa sehat?\n",
            "apakah kamu sakit?\n",
            "bagaimana kabar mu hari ini\n",
            "apakah kamu pernah merasakan lelah\n",
            "kamu ini apa\n",
            "\n",
            "Data Jawaban Sebelum Pengacakan:\n",
            "<START> halo! apa yang bisa saya bantu? <END>\n",
            "<START> hai, kamu butuh bantuan apa? <END>\n",
            "<START> selamat pagi! apa yang bisa saya lakukan untuk anda? <END>\n",
            "<START> waalaikumsalam <END>\n",
            "<START> halo! ini adalah chatbot informasi seminar-fst <END>\n",
            "<START> selamat pagi! apa yang bisa saya lakukan untuk anda? <END>\n",
            "<START> selamat siang! apa yang bisa saya lakukan untuk anda? <END>\n",
            "<START> selamat datang, bagaimana saya bisa membantu anda? <END>\n",
            "<START> halo! ini adalah chatbot informasi seminar-fst <END>\n",
            "<START> selamat malam, bagaimana saya bisa membantu anda? <END>\n",
            "<START> halo! selamat datang, bagaimana saya bisa membantu anda? <END>\n",
            "<START> halo! selamat sore, bagaimana saya bisa membantu anda? <END>\n",
            "<START> selamat sore <END>\n",
            "<START> halo! saya baik, terima kasih. bagaimana dengan anda? <END>\n",
            "<START> bagaimana saya dapat membantu anda hari ini? <END>\n",
            "<START> saya adalah program komputer, jadi saya tidak memiliki kesehatan fisik, tetapi saya siap membantu anda <END>\n",
            "<START> saya adalah program komputer, jadi saya tidak memiliki kesehatan fisik, tetapi saya siap membantu anda <END>\n",
            "<START> tentu saja kabar saya baik dan siap membantu anda <END>\n",
            "<START> saya adalah program komputer yang tidak bisa merasa lelah <END>\n",
            "<START> saya adalah program komputer yang akan membantu menjawab rasa penasaran anda seputar layanan administasi di fakultas sains dan teknologi <END>\n",
            "\n",
            "Data Pertanyaan Setelah Pengacakan:\n",
            "bagaimana caranya bagi mahasiswa untuk meminta surat keterangan masih kuliah dengan benar?\n",
            "bagaimana persyaratan mendaftar seminar hasil ta di universitas ini?\n",
            "apa yang menjadi fokus utama dalam menilai hasil sidang tugas akhir\n",
            "apa saja kriteria kerja praktek di program studi teknik elektro?\n",
            "bagaimana jika program studi mencari perusahaan untuk kerja praktek mahasiswa?\n",
            "apa yang menjadi manfaat utama dari pelaksanaan kerja praktek bagi mahasiswa?\n",
            "apakah ada biaya yang harus dibayarkan saat mendaftar seminar proposal mahasiswa?\n",
            "sebutkan persyaratan yang dibutuhkan untuk mengajukan seminar kerja praktek.\n",
            "seperti apa ciri-ciri laporan tugas akhir yang sudah selesai?\n",
            "apa saja ketentuan umum yang berlaku untuk pelaksanaan kerja praktek?\n",
            "cara daftar seminar?\n",
            "bagaimana cara memastikan bahwa dokumen yang disiapkan sudah sesuai untuk surat penunjukkan pembimbing?\n",
            "apa tujuan dari seminar proposal dan bagaimana prosesnya?\n",
            "apa saja persyaratan mengikuti sidang tugas akhir dan bagaimana prosesnya?\n",
            "apa yang harus dilakukan mahasiswa setelah menyepakati jadwal seminar proposal ta?\n",
            "adakah pembatasan bagi mahasiswa terkait pengajuan surat keterangan masih kuliah dalam satu periode akademik?\n",
            "jelaskan apa saja bentuk kp yang ada di fakultas sains dan teknologi\n",
            "bagaimana ketentuan untuk mempublikasikan ta berbasis paper?\n",
            "bagaimana jika program studi mencari perusahaan untuk kerja praktek mahasiswa?\n",
            "apa yang harus dilakukan untuk mendaftar sidang tugas akhir dan apa syaratnya?\n",
            "\n",
            "Data Jawaban Setelah Pengacakan:\n",
            "<START> caranya bagi mahasiswa untuk meminta surat keterangan masih kuliah dengan benar adalah dengan menyiapkan berkas persyaratan terlebih dahulu, seperti formulir pengajuan dan fotokopi sk pns orang tua, lalu melakukan pengajuan secara online melalui website seminar-fst.uin-suska.ac.id. <END>\n",
            "<START> persyaratan mendaftar seminar hasil ta di universitas ini meliputi: lulu mata kuliah wajib, total sks yang sudah diambil minimal 144, tidak memiliki nilai e, memiliki surat penunjukkan pembimbing yang masih aktif, sudah melakukan bimbingan minimal 5 kali setelah seminar proposal, sudah menghadiri seminar hasil mahasiswa lain minimal 5 kali, menyerahkan laporan tugas akhir sesuai kriteria dengan maksimal plagiarisme 35%, serta menyerahkan laporan kepada dosen pembimbing dan dosen penguji yang dibuktikan melalui tanda tangan pada form pendaftaran seminar hasil tugas akhir. <END>\n",
            "<START> beberapa kriteria yang menjadi penilaian kelulusan sidang tugas akhir adalah kompetensi dasar keislaman, sikap pada saat presentasi, kemampuan presentasi dan penguasaan materi. kemudian urgensi terhadap masalah penelitian, relevansi referensi dengan judul penelitian, kesesuaian metodologi dengan pembahasan, teknik pengumpulan data, analisa, perancangan dan pengujian sesuai dengan standar laporan tugas akhir. hasil penelitian sesuai dengan standar laporan tugas akhir dan memiliki kesesuaian dengan permasalahan.hasil sidang ta dapat diluluskan apabila total penilaian rata-rata dari pembimbing dan penguji sama dengan atau lebih dari 55. <END>\n",
            "<START> kriteria untuk kerja praktek di program studi teknik elektro mencakup beberapa hal. pertama, mahasiswa harus menyerahkan formulir kp 1 yang sudah ditandatangani oleh jurusan. kedua, mahasiswa harus menyerahkan transkrip nilai sementara yang menunjukkan telah lulu minimal 80 sks. ketiga, mahasiswa harus telah mengambil mata kuliah dasar komputer dan pemrograman, dasar sistem telekomunikasi, pengukuran dan instrumentasi, dasar elektronika, sistem kendali, teknik digital, dan mata kuliah mikroprosesor. selanjutnya, mahasiswa harus sudah lulu atau sedang mengambil mata kuliah praktikum teknik elektro rangkaian listrik. <END>\n",
            "<START> jika program studi mencari perusahaan untuk kerja praktek mahasiswa, prosedurnya adalah sebagai berikut: jurusan menghubungi perusahaan atau instansi yang cocok untuk memberikan tempat kerja. lingkup dan batasan waktu kerja ditentukan sesuai kebutuhan kerja praktek, dengan topik yang jelas. jurusan menyeleksi topik kerja, mengevaluasi kapasitas tempat kerja, dan membuat daftar tempat kerja praktek. data tentang peluang kerja praktek disampaikan kepada mahasiswa yang memenuhi syarat. mahasiswa mengisi formulir pengajuan kerja praktek. jurusan menentukan tempat kerja praktek sesuai permintaan mahasiswa. jika tempat yang diminati banyak mahasiswa, jurusan mencari solusi lain. jurusan mengajukan izin kerja praktek ke perusahaan. perusahaan memberikan surat penerimaan atau penolakan kepada jurusan, yang kemudian disampaikan kepada mahasiswa. <END>\n",
            "<START> manfaat utama dari kerja praktek adalah memberikan kesempatan kepada mahasiswa untuk mengaplikasikan pengetahuan dan keterampilan yang dimiliki dalam dunia nyata. selain itu, kerja praktek juga memungkinkan mahasiswa untuk mengenal cara kerja di masyarakat dan melatih sikap kerja profesional. <END>\n",
            "<START> tidak ada biaya pendaftaran yang diperlukan untuk seminar proposal mahasiswa. namun, pastikan untuk mempersiapkan berkas dengan benar sesuai dengan persyaratan yang ditetapkan. <END>\n",
            "<START> mahasiswa perlu memenuhi beberapa persyaratan administrasi. ini termasuk surat selesai kp dari perusahaan, bukti laporan kp yang telah disetujui oleh pembimbing, bukti kehadiran minimal lima kali di seminar kp, kartu bimbingan kp minimal lima kali, bukti penilaian dari perusahaan, surat permohonan seminar kp yang ditandatangani oleh jurusan, dan form biodata pembimbing perusahaan. <END>\n",
            "<START> laporan tugas akhir yang telah selesai memiliki karakteristik yang mencakup beberapa aspek, seperti pendahuluan, tinjauan pustaka, metodologi penelitian, pengumpulan dan analisis data, serta kesimpulan dan saran. selain itu, laporan juga harus memiliki halaman judul, lembar pengesahan, persetujuan, kekayaan hak intelektual, abstrak, kata pengantar, daftar isi, daftar pustaka, daftar riwayat hidup, daftar gambar, daftar tabel, daftar rumus, dan lampiran. penulisan laporan harus didukung oleh minimal 15 referensi, termasuk 10 jurnal terkait dalam lima tahun terakhir. penyerahan laporan dilakukan kepada dosen pembimbing dan dosen penguji, yang ditandai dengan tanda tangan pada formulir pendaftaran seminar hasil tugas akhir. <END>\n",
            "<START> ketentuan umum untuk pelaksanaan kerja praktek termasuk menyelesaikan minimal 80 sks mata kuliah dan tidak diperkenankan lebih dari satu mahasiswa melakukan kerja praktek dengan materi yang sama pada semester yang sama. tempat kerja praktek harus merupakan instansi/universitas atau perusahaan/organisasi yang berbadan hukum dan menggunakan teknologi informasi dalam prose kerjanya. <END>\n",
            "<START> untuk mendaftar seminar, anda dapat memulainya dengan mengajukan permohonan melalui website seminar-fst.uin-suska.ac.id. setelah mengajukan secara online, langkah berikutnya adalah melakukan verifikasi berkas melalui program studi masing-masing mahasiswa. setelah berkas diverifikasi, koordinator kp/ta akan menentukan jadwal dan menunjuk dosen penguji. <END>\n",
            "<START> pastikan untuk memverifikasi bahwa dokumen sesuai dengan persyaratan di tiap program studi di fakultas sains dan teknologi. konfirmasikan dengan prodi masing-masing. <END>\n",
            "<START> tujuan dari seminar proposal adalah untuk menilai kelayakan topik, metodologi, dan isi proposal yang disiapkan oleh mahasiswa dengan bimbingan dari dosen pembimbing tugas akhir. prosesnya melibatkan pendaftaran seminar proposal melalui koordinator tugas akhir kepada ketua prodi oleh mahasiswa yang memenuhi syarat. <END>\n",
            "<START> persyaratan mengikuti sidang tugas akhir mencakup kehadiran mahasiswa yang bersangkutan, dosen pembimbing, semua dosen penguji, dan ketua sidang. selama sidang, mahasiswa harus menghadiri sendiri dan tidak diperkenankan ditemani oleh mahasiswa lain. <END>\n",
            "<START> mahasiswa mempersiapkan berkas administrasi dan hal lainnya yang diperlukan untuk pelaksanaan seminar proposal <END>\n",
            "<START> iya, mahasiswa hanya dapat mengajukan surat keterangan masih kuliah satu kali dalam satu semester. <END>\n",
            "<START> secara umum, bentuk kerja praktek ada tiga yaitu kajian ilmiah merupakan kerja praktek yang menganalisis teknik, metode dan teori. hasil akhir dari kajian ilmiah dapat berupa pengujian model atau perangkat, atau juga dapat berupa analisis. bentuk kedua adalah kajian industri, merupakan kerja praktek yang mengembangkan suatu perangkat atau data berdasarkan kebutuhan dari industri atau menganalisis perangkat atau sistem yang ada di suatu industri. analisis kajian industri tetap harus didasari dengan kajian ilmiah yang mengarah ke topik tersebut. hasil akhir dari kajian industri ini dapat berupa rancangan, pengembangan suatu perangkat data untuk kebutuhan industri, atau analisis dari sistem yang ada di industri tersebut. jenis ketiga adalah pengembangan perangkat, merupakan kerja praktek yang hasil akhirnya berupa rancangan perangkat atau hasil implementasi rancangan perangkat <END>\n",
            "<START> ta paper based diakui jika mahasiswa menjadi penulis pertama. dengan izin dari dosen pembimbing, mahasiswa dapat mempublikasikan artikelnya di jurnal terindex moraref, sinta, doaj. juga bisa pada proceeding seminar internasional dan nasional, serta pada book chapter internasional dan nasional. <END>\n",
            "<START> jika program studi yang mencari perusahaan untuk kerja praktek mahasiswa, prosedurnya adalah sebagai berikut: jurusan menghubungi perusahaan atau instansi yang cocok untuk memberikan tempat kerja. lingkup dan batasan waktu kerja ditentukan sesuai kebutuhan kerja praktek, dengan topik yang jelas. jurusan menyeleksi topik kerja, mengevaluasi kapasitas tempat kerja, dan membuat daftar tempat kerja praktek. data tentang peluang kerja praktek disampaikan kepada mahasiswa yang memenuhi syarat. mahasiswa mengisi formulir pengajuan kerja praktek. jurusan menentukan tempat kerja praktek sesuai permintaan mahasiswa. jika tempat yang diminati banyak mahasiswa, jurusan mencari solusi lain. jurusan mengajukan izin kerja praktek ke perusahaan. perusahaan memberikan surat penerimaan atau penolakan kepada jurusan, yang kemudian disampaikan kepada mahasiswa. <END>\n",
            "<START> untuk mendaftar sidang tugas akhir, mahasiswa harus memastikan kelulusan semua mata kuliah wajib, total sks minimal 144, tidak ada nilai e, jumlah nilai d dalam bata ketentuan, memiliki surat penunjukkan pembimbing yang masih berlaku, serta telah melakukan bimbingan minimal 6 kali setelah seminar proposal. selain itu, mahasiswa juga harus memastikan bahwa maksimal plagiarisme pada tugas akhir skripsi tidak melebihi 35%, laporan tugas akhir telah disetujui oleh dosen pembimbing, dan format laporan sesuai dengan ketentuan yang berlaku. mahasiswa juga harus memiliki sertifikat pbak, sertifikat mentoring, dan sertifikat kuliah kerja nyata (kkn), serta menyelesaikan hafalan juz 30. <END>\n"
          ]
        }
      ],
      "source": [
        "# Contoh data sebelum pengacakan\n",
        "print(\"Data Pertanyaan Sebelum Pengacakan:\")\n",
        "for i in range(20):  # Cetak lima contoh pertama\n",
        "    print(cleaned_questions[i])\n",
        "\n",
        "print(\"\\nData Jawaban Sebelum Pengacakan:\")\n",
        "for i in range(20):  # Cetak lima contoh pertama\n",
        "    print(cleaned_answers[i])\n",
        "\n",
        "# Contoh data setelah pengacakan\n",
        "print(\"\\nData Pertanyaan Setelah Pengacakan:\")\n",
        "for i in range(20):  # Cetak lima contoh pertama\n",
        "    print(shuffled_questions[i])\n",
        "\n",
        "print(\"\\nData Jawaban Setelah Pengacakan:\")\n",
        "for i in range(20):  # Cetak lima contoh pertama\n",
        "    print(shuffled_answers[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1i2-jJ-llMG",
        "outputId": "77b38c48-4f12-4868-ff96-8e6158465322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total conversations in dataset: 1149\n"
          ]
        }
      ],
      "source": [
        "print(f'Total conversations in dataset: {len(all_conversations)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSLQlbm0EvMb"
      },
      "source": [
        "###Data Restructuring for Encoder Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMc3JRu0mDAi",
        "outputId": "e5cc87bc-59e3-4786-d191-729e718cb442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size: 1779\n"
          ]
        }
      ],
      "source": [
        "#Jangan di RUN\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(cleaned_questions + cleaned_answers)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "#Encoder Input Data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(cleaned_questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "encoder_input_data = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "#Decoder Input Data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(cleaned_answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "decoder_input_data = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "\n",
        "#Decoder Output Data\n",
        "for i in range(len(tokenized_answers)):\n",
        "  tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "\n",
        "decoder_output_data = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding=\n",
        "                                 'post')\n",
        "\n",
        "\n",
        "print(f'Vocab Size: {VOCAB_SIZE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-7R5N5mCX_x",
        "outputId": "45351d15-7845-4866-aba4-af813484c9e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size: 1301\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(shuffled_questions + shuffled_answers)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "#Encoder Input Data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(shuffled_questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "encoder_input_data = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "#Decoder Input Data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(shuffled_answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "decoder_input_data = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "\n",
        "#Decoder Output Data\n",
        "for i in range(len(tokenized_answers)):\n",
        "  tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "\n",
        "decoder_output_data = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding=\n",
        "                                 'post')\n",
        "\n",
        "\n",
        "print(f'Vocab Size: {VOCAB_SIZE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqUBwbgqeV4n",
        "outputId": "d08419fa-eeca-4f11-d8f3-eeef3815a829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer berhasil disimpan dalam file tokenizer.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Simpan tokenizer ke dalam file pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
        "    pickle.dump(tokenizer, tokenizer_file)\n",
        "\n",
        "print(\"Tokenizer berhasil disimpan dalam file tokenizer.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXwttYekE9tF"
      },
      "source": [
        "###Build Bi-LSTM Model using Seq2Seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaoKPepFpbKt",
        "outputId": "7b97a360-7f3d-4936-ad73-efe0e40e14d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)       [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)    (None, None, 128)            166528    ['input_15[0][0]']            \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)       [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirecti  [(None, 200),                183200    ['embedding_10[0][0]']        \n",
            " onal)                        (None, 100),                                                        \n",
            "                              (None, 100),                                                        \n",
            "                              (None, 100),                                                        \n",
            "                              (None, 100)]                                                        \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)    (None, None, 128)            166528    ['input_16[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 200)                  0         ['bidirectional_5[0][1]',     \n",
            " e)                                                                  'bidirectional_5[0][3]']     \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 200)                  0         ['bidirectional_5[0][2]',     \n",
            " e)                                                                  'bidirectional_5[0][4]']     \n",
            "                                                                                                  \n",
            " lstm_11 (LSTM)              [(None, None, 200),          263200    ['embedding_11[0][0]',        \n",
            "                              (None, 200),                           'concatenate_10[0][0]',      \n",
            "                              (None, 200)]                           'concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, None, 1301)           261501    ['lstm_11[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1040957 (3.97 MB)\n",
            "Trainable params: 1040957 (3.97 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# create seq2seq bidirectional lstm model\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "HIDDEN_DIM = 100\n",
        "def build_bi_lstm(dropout_rate=0.2):\n",
        "\n",
        "    # encoder\n",
        "    enc_inputs = Input(shape=(None,))\n",
        "    enc_embedding = Embedding(VOCAB_SIZE, 128, mask_zero=True)(enc_inputs)\n",
        "    enc_outputs, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(HIDDEN_DIM, return_state=True))(enc_embedding)\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "    state_c = Concatenate()([forward_c, backward_c])\n",
        "    enc_states = [state_h, state_c]\n",
        "\n",
        "    # dropout layer\n",
        "    dropout_layer = Dropout(rate=dropout_rate)\n",
        "\n",
        "    # decoder\n",
        "    dec_inputs = Input(shape=(None,))\n",
        "    dec_embedding = Embedding(VOCAB_SIZE, 128, mask_zero=True)(dec_inputs)\n",
        "    dec_lstm = LSTM(HIDDEN_DIM * 2, return_state=True, return_sequences=True)\n",
        "    dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state=enc_states)\n",
        "    dec_outputs_dropout = dropout_layer(dec_outputs)  # Adding dropout layer\n",
        "    dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "    output = dec_dense(dec_outputs)\n",
        "    bi_lstm = Model([enc_inputs, dec_inputs], output)\n",
        "    return bi_lstm, enc_inputs, enc_states, dec_inputs, dec_embedding, dec_lstm, dec_dense\n",
        "\n",
        "# summary of the model\n",
        "model = build_bi_lstm()\n",
        "bi_lstm = model[0]\n",
        "bi_lstm.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "bi_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fEixfmzrHhd",
        "outputId": "e97ad2e6-b615-453b-8733-9ed5003169d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current batch size: 8\n",
            "Epoch 1/500\n",
            "130/130 [==============================] - 32s 128ms/step - loss: 5.8722 - accuracy: 0.0509 - val_loss: 5.5630 - val_accuracy: 0.0756\n",
            "Epoch 2/500\n",
            "130/130 [==============================] - 7s 56ms/step - loss: 5.1062 - accuracy: 0.1126 - val_loss: 4.9394 - val_accuracy: 0.1679\n",
            "Epoch 3/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 4.3585 - accuracy: 0.2263 - val_loss: 4.2431 - val_accuracy: 0.2508\n",
            "Epoch 4/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 3.7102 - accuracy: 0.3085 - val_loss: 3.7096 - val_accuracy: 0.3240\n",
            "Epoch 5/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 3.1829 - accuracy: 0.3902 - val_loss: 3.2799 - val_accuracy: 0.3869\n",
            "Epoch 6/500\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 2.7383 - accuracy: 0.4655 - val_loss: 2.8720 - val_accuracy: 0.4645\n",
            "Epoch 7/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 2.3967 - accuracy: 0.5283 - val_loss: 2.5834 - val_accuracy: 0.5115\n",
            "Epoch 8/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 2.0969 - accuracy: 0.5815 - val_loss: 2.3252 - val_accuracy: 0.5659\n",
            "Epoch 9/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 1.8468 - accuracy: 0.6272 - val_loss: 2.1177 - val_accuracy: 0.6008\n",
            "Epoch 10/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 1.6376 - accuracy: 0.6670 - val_loss: 1.9431 - val_accuracy: 0.6389\n",
            "Epoch 11/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 1.4785 - accuracy: 0.6968 - val_loss: 1.8402 - val_accuracy: 0.6578\n",
            "Epoch 12/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 1.3398 - accuracy: 0.7257 - val_loss: 1.7051 - val_accuracy: 0.6873\n",
            "Epoch 13/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 1.2174 - accuracy: 0.7506 - val_loss: 1.6075 - val_accuracy: 0.7118\n",
            "Epoch 14/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 1.1007 - accuracy: 0.7737 - val_loss: 1.5197 - val_accuracy: 0.7300\n",
            "Epoch 15/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.9993 - accuracy: 0.7922 - val_loss: 1.4538 - val_accuracy: 0.7449\n",
            "Epoch 16/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.9288 - accuracy: 0.8096 - val_loss: 1.3861 - val_accuracy: 0.7574\n",
            "Epoch 17/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.8573 - accuracy: 0.8249 - val_loss: 1.3421 - val_accuracy: 0.7672\n",
            "Epoch 18/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.7748 - accuracy: 0.8403 - val_loss: 1.2861 - val_accuracy: 0.7805\n",
            "Epoch 19/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.7213 - accuracy: 0.8517 - val_loss: 1.2584 - val_accuracy: 0.7823\n",
            "Epoch 20/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.6685 - accuracy: 0.8630 - val_loss: 1.2240 - val_accuracy: 0.7928\n",
            "Epoch 21/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.6117 - accuracy: 0.8743 - val_loss: 1.2379 - val_accuracy: 0.7863\n",
            "Epoch 22/500\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 0.5855 - accuracy: 0.8777 - val_loss: 1.1626 - val_accuracy: 0.8081\n",
            "Epoch 23/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.5296 - accuracy: 0.8919 - val_loss: 1.1436 - val_accuracy: 0.8108\n",
            "Epoch 24/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.4835 - accuracy: 0.8990 - val_loss: 1.1207 - val_accuracy: 0.8154\n",
            "Epoch 25/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.4496 - accuracy: 0.9066 - val_loss: 1.0885 - val_accuracy: 0.8234\n",
            "Epoch 26/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.4208 - accuracy: 0.9122 - val_loss: 1.0907 - val_accuracy: 0.8203\n",
            "Epoch 27/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.3940 - accuracy: 0.9192 - val_loss: 1.0782 - val_accuracy: 0.8281\n",
            "Epoch 28/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.3632 - accuracy: 0.9242 - val_loss: 1.0651 - val_accuracy: 0.8303\n",
            "Epoch 29/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.3380 - accuracy: 0.9288 - val_loss: 1.0672 - val_accuracy: 0.8310\n",
            "Epoch 30/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.3149 - accuracy: 0.9343 - val_loss: 1.0538 - val_accuracy: 0.8337\n",
            "Epoch 31/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.2943 - accuracy: 0.9384 - val_loss: 1.0486 - val_accuracy: 0.8363\n",
            "Epoch 32/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.2835 - accuracy: 0.9417 - val_loss: 1.0474 - val_accuracy: 0.8348\n",
            "Epoch 33/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.2627 - accuracy: 0.9439 - val_loss: 1.0399 - val_accuracy: 0.8361\n",
            "Epoch 34/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.2427 - accuracy: 0.9494 - val_loss: 1.0347 - val_accuracy: 0.8374\n",
            "Epoch 35/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.2245 - accuracy: 0.9534 - val_loss: 1.0312 - val_accuracy: 0.8403\n",
            "Epoch 36/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.2138 - accuracy: 0.9563 - val_loss: 1.0276 - val_accuracy: 0.8428\n",
            "Epoch 37/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.1969 - accuracy: 0.9592 - val_loss: 1.0225 - val_accuracy: 0.8423\n",
            "Epoch 38/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.1859 - accuracy: 0.9623 - val_loss: 1.0308 - val_accuracy: 0.8372\n",
            "Epoch 39/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.1775 - accuracy: 0.9635 - val_loss: 1.0384 - val_accuracy: 0.8446\n",
            "Epoch 40/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.1748 - accuracy: 0.9633 - val_loss: 1.0254 - val_accuracy: 0.8461\n",
            "Epoch 41/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.1538 - accuracy: 0.9689 - val_loss: 1.0227 - val_accuracy: 0.8468\n",
            "Epoch 42/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.1461 - accuracy: 0.9702 - val_loss: 1.0223 - val_accuracy: 0.8488\n",
            "Epoch 43/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.1355 - accuracy: 0.9724 - val_loss: 1.0286 - val_accuracy: 0.8468\n",
            "Epoch 44/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.1289 - accuracy: 0.9736 - val_loss: 1.0249 - val_accuracy: 0.8475\n",
            "Epoch 45/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.1209 - accuracy: 0.9759 - val_loss: 1.0390 - val_accuracy: 0.8452\n",
            "Epoch 46/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.1169 - accuracy: 0.9761 - val_loss: 1.0456 - val_accuracy: 0.8443\n",
            "Epoch 47/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.1092 - accuracy: 0.9778 - val_loss: 1.0328 - val_accuracy: 0.8499\n",
            "Epoch 48/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.1008 - accuracy: 0.9803 - val_loss: 1.0450 - val_accuracy: 0.8446\n",
            "Epoch 49/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0961 - accuracy: 0.9801 - val_loss: 1.0423 - val_accuracy: 0.8510\n",
            "Epoch 50/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0891 - accuracy: 0.9822 - val_loss: 1.0403 - val_accuracy: 0.8481\n",
            "Epoch 51/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0834 - accuracy: 0.9829 - val_loss: 1.0571 - val_accuracy: 0.8463\n",
            "Epoch 52/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0800 - accuracy: 0.9852 - val_loss: 1.0500 - val_accuracy: 0.8497\n",
            "Epoch 53/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0760 - accuracy: 0.9849 - val_loss: 1.0693 - val_accuracy: 0.8488\n",
            "Epoch 54/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0724 - accuracy: 0.9855 - val_loss: 1.0622 - val_accuracy: 0.8535\n",
            "Epoch 55/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0725 - accuracy: 0.9850 - val_loss: 1.0639 - val_accuracy: 0.8512\n",
            "Epoch 56/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0661 - accuracy: 0.9869 - val_loss: 1.0740 - val_accuracy: 0.8492\n",
            "Epoch 57/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0605 - accuracy: 0.9886 - val_loss: 1.0725 - val_accuracy: 0.8515\n",
            "Epoch 58/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0588 - accuracy: 0.9891 - val_loss: 1.0912 - val_accuracy: 0.8508\n",
            "Epoch 59/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0558 - accuracy: 0.9899 - val_loss: 1.0890 - val_accuracy: 0.8541\n",
            "Epoch 60/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0568 - accuracy: 0.9888 - val_loss: 1.0908 - val_accuracy: 0.8526\n",
            "Epoch 61/500\n",
            "130/130 [==============================] - 5s 39ms/step - loss: 0.0530 - accuracy: 0.9898 - val_loss: 1.0974 - val_accuracy: 0.8510\n",
            "Epoch 62/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0491 - accuracy: 0.9907 - val_loss: 1.1020 - val_accuracy: 0.8532\n",
            "Epoch 63/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0447 - accuracy: 0.9920 - val_loss: 1.0900 - val_accuracy: 0.8541\n",
            "Epoch 64/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0403 - accuracy: 0.9926 - val_loss: 1.1092 - val_accuracy: 0.8550\n",
            "Epoch 65/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0404 - accuracy: 0.9927 - val_loss: 1.1121 - val_accuracy: 0.8555\n",
            "Epoch 66/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0491 - accuracy: 0.9902 - val_loss: 1.1202 - val_accuracy: 0.8490\n",
            "Epoch 67/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0453 - accuracy: 0.9906 - val_loss: 1.1237 - val_accuracy: 0.8539\n",
            "Epoch 68/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0404 - accuracy: 0.9916 - val_loss: 1.1172 - val_accuracy: 0.8559\n",
            "Epoch 69/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0384 - accuracy: 0.9921 - val_loss: 1.1214 - val_accuracy: 0.8561\n",
            "Epoch 70/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0362 - accuracy: 0.9922 - val_loss: 1.1268 - val_accuracy: 0.8532\n",
            "Epoch 71/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0307 - accuracy: 0.9942 - val_loss: 1.1317 - val_accuracy: 0.8550\n",
            "Epoch 72/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0302 - accuracy: 0.9937 - val_loss: 1.1364 - val_accuracy: 0.8543\n",
            "Epoch 73/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0274 - accuracy: 0.9944 - val_loss: 1.1444 - val_accuracy: 0.8550\n",
            "Epoch 74/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 1.1444 - val_accuracy: 0.8543\n",
            "Epoch 75/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0328 - accuracy: 0.9930 - val_loss: 1.1593 - val_accuracy: 0.8508\n",
            "Epoch 76/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0312 - accuracy: 0.9936 - val_loss: 1.1522 - val_accuracy: 0.8523\n",
            "Epoch 77/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0266 - accuracy: 0.9943 - val_loss: 1.1604 - val_accuracy: 0.8557\n",
            "Epoch 78/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0246 - accuracy: 0.9950 - val_loss: 1.1600 - val_accuracy: 0.8552\n",
            "Epoch 79/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 1.1709 - val_accuracy: 0.8546\n",
            "Epoch 80/500\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 1.1681 - val_accuracy: 0.8555\n",
            "Epoch 81/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0250 - accuracy: 0.9948 - val_loss: 1.1846 - val_accuracy: 0.8552\n",
            "Epoch 82/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0218 - accuracy: 0.9953 - val_loss: 1.1860 - val_accuracy: 0.8519\n",
            "Epoch 83/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 1.1988 - val_accuracy: 0.8546\n",
            "Epoch 84/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 1.1970 - val_accuracy: 0.8541\n",
            "Epoch 85/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 1.2022 - val_accuracy: 0.8563\n",
            "Epoch 86/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 1.2182 - val_accuracy: 0.8523\n",
            "Epoch 87/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 1.2101 - val_accuracy: 0.8541\n",
            "Epoch 88/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 1.2206 - val_accuracy: 0.8523\n",
            "Epoch 89/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 1.2404 - val_accuracy: 0.8530\n",
            "Epoch 90/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0143 - accuracy: 0.9968 - val_loss: 1.2417 - val_accuracy: 0.8526\n",
            "Epoch 91/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 1.2357 - val_accuracy: 0.8523\n",
            "Epoch 92/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 1.2418 - val_accuracy: 0.8517\n",
            "Epoch 93/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 1.2703 - val_accuracy: 0.8495\n",
            "Epoch 94/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 1.2677 - val_accuracy: 0.8528\n",
            "Epoch 95/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 1.2858 - val_accuracy: 0.8506\n",
            "Epoch 96/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 1.2969 - val_accuracy: 0.8539\n",
            "Epoch 97/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 1.2864 - val_accuracy: 0.8501\n",
            "Epoch 98/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 1.2668 - val_accuracy: 0.8528\n",
            "Epoch 99/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 1.2733 - val_accuracy: 0.8530\n",
            "Epoch 100/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 1.2987 - val_accuracy: 0.8523\n",
            "Epoch 101/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 1.2961 - val_accuracy: 0.8495\n",
            "Epoch 102/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 1.3034 - val_accuracy: 0.8501\n",
            "Epoch 103/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 1.3055 - val_accuracy: 0.8543\n",
            "Epoch 104/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 1.3029 - val_accuracy: 0.8519\n",
            "Epoch 105/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 1.3253 - val_accuracy: 0.8528\n",
            "Epoch 106/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 1.3200 - val_accuracy: 0.8535\n",
            "Epoch 107/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.3175 - val_accuracy: 0.8532\n",
            "Epoch 108/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 1.3246 - val_accuracy: 0.8543\n",
            "Epoch 109/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.3266 - val_accuracy: 0.8537\n",
            "Epoch 110/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 1.3218 - val_accuracy: 0.8559\n",
            "Epoch 111/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 1.3345 - val_accuracy: 0.8537\n",
            "Epoch 112/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 1.3404 - val_accuracy: 0.8508\n",
            "Epoch 113/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 1.3693 - val_accuracy: 0.8452\n",
            "Epoch 114/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0233 - accuracy: 0.9946 - val_loss: 1.3571 - val_accuracy: 0.8526\n",
            "Epoch 115/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 1.3646 - val_accuracy: 0.8521\n",
            "Epoch 116/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 1.3602 - val_accuracy: 0.8532\n",
            "Epoch 117/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 1.3662 - val_accuracy: 0.8532\n",
            "Epoch 118/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 1.3683 - val_accuracy: 0.8537\n",
            "Epoch 119/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 1.3717 - val_accuracy: 0.8535\n",
            "Epoch 120/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.3703 - val_accuracy: 0.8552\n",
            "Epoch 121/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.3772 - val_accuracy: 0.8557\n",
            "Epoch 122/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 1.3745 - val_accuracy: 0.8555\n",
            "Epoch 123/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.3916 - val_accuracy: 0.8552\n",
            "Epoch 124/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 1.3803 - val_accuracy: 0.8555\n",
            "Epoch 125/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 1.3862 - val_accuracy: 0.8546\n",
            "Epoch 126/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 1.3922 - val_accuracy: 0.8546\n",
            "Epoch 127/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 1.3966 - val_accuracy: 0.8528\n",
            "Epoch 128/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 1.3951 - val_accuracy: 0.8548\n",
            "Epoch 129/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 1.4014 - val_accuracy: 0.8552\n",
            "Epoch 130/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 1.3969 - val_accuracy: 0.8535\n",
            "Epoch 131/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 1.3814 - val_accuracy: 0.8535\n",
            "Epoch 132/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 1.3938 - val_accuracy: 0.8561\n",
            "Epoch 133/500\n",
            "130/130 [==============================] - 5s 41ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.3866 - val_accuracy: 0.8532\n",
            "Epoch 134/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 1.3985 - val_accuracy: 0.8557\n",
            "Epoch 135/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.4002 - val_accuracy: 0.8552\n",
            "Epoch 136/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 1.4115 - val_accuracy: 0.8503\n",
            "Epoch 137/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 1.4125 - val_accuracy: 0.8543\n",
            "Epoch 138/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.4490 - val_accuracy: 0.8483\n",
            "Epoch 139/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 1.4436 - val_accuracy: 0.8512\n",
            "Epoch 140/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.4329 - val_accuracy: 0.8526\n",
            "Epoch 141/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.4437 - val_accuracy: 0.8543\n",
            "Epoch 142/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 1.4413 - val_accuracy: 0.8528\n",
            "Epoch 143/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 1.4494 - val_accuracy: 0.8528\n",
            "Epoch 144/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 1.4520 - val_accuracy: 0.8532\n",
            "Epoch 145/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 1.4402 - val_accuracy: 0.8528\n",
            "Epoch 146/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 1.4418 - val_accuracy: 0.8519\n",
            "Epoch 147/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 1.4626 - val_accuracy: 0.8539\n",
            "Epoch 148/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.4646 - val_accuracy: 0.8537\n",
            "Epoch 149/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 1.4570 - val_accuracy: 0.8530\n",
            "Epoch 150/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 1.4988 - val_accuracy: 0.8421\n",
            "Epoch 151/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 1.4783 - val_accuracy: 0.8475\n",
            "Epoch 152/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 1.4615 - val_accuracy: 0.8535\n",
            "Epoch 153/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 1.4691 - val_accuracy: 0.8546\n",
            "Epoch 154/500\n",
            "130/130 [==============================] - 4s 35ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 1.4711 - val_accuracy: 0.8561\n",
            "Epoch 155/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 1.4717 - val_accuracy: 0.8550\n",
            "Epoch 156/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.4784 - val_accuracy: 0.8557\n",
            "Epoch 157/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.4728 - val_accuracy: 0.8550\n",
            "Epoch 158/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.4794 - val_accuracy: 0.8548\n",
            "Epoch 159/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.4799 - val_accuracy: 0.8561\n",
            "Epoch 160/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.4794 - val_accuracy: 0.8555\n",
            "Epoch 161/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.4840 - val_accuracy: 0.8559\n",
            "Epoch 162/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.4832 - val_accuracy: 0.8552\n",
            "Epoch 163/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.4882 - val_accuracy: 0.8559\n",
            "Epoch 164/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.4892 - val_accuracy: 0.8557\n",
            "Epoch 165/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 1.4924 - val_accuracy: 0.8555\n",
            "Epoch 166/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 1.4936 - val_accuracy: 0.8563\n",
            "Epoch 167/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 1.4956 - val_accuracy: 0.8570\n",
            "Epoch 168/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.5010 - val_accuracy: 0.8579\n",
            "Epoch 169/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.4993 - val_accuracy: 0.8566\n",
            "Epoch 170/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.5070 - val_accuracy: 0.8563\n",
            "Epoch 171/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 1.5056 - val_accuracy: 0.8559\n",
            "Epoch 172/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.5052 - val_accuracy: 0.8570\n",
            "Epoch 173/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.5390 - val_accuracy: 0.8510\n",
            "Epoch 174/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0377 - accuracy: 0.9885 - val_loss: 1.6026 - val_accuracy: 0.8346\n",
            "Epoch 175/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 1.5367 - val_accuracy: 0.8530\n",
            "Epoch 176/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 1.5307 - val_accuracy: 0.8515\n",
            "Epoch 177/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 1.5162 - val_accuracy: 0.8550\n",
            "Epoch 178/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.5147 - val_accuracy: 0.8552\n",
            "Epoch 179/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.5223 - val_accuracy: 0.8541\n",
            "Epoch 180/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.5267 - val_accuracy: 0.8546\n",
            "Epoch 181/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.5251 - val_accuracy: 0.8561\n",
            "Epoch 182/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.5305 - val_accuracy: 0.8550\n",
            "Epoch 183/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 1.5329 - val_accuracy: 0.8552\n",
            "Epoch 184/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 1.5351 - val_accuracy: 0.8543\n",
            "Epoch 185/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.5377 - val_accuracy: 0.8539\n",
            "Epoch 186/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.5353 - val_accuracy: 0.8550\n",
            "Epoch 187/500\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.5393 - val_accuracy: 0.8559\n",
            "Epoch 188/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 1.5436 - val_accuracy: 0.8561\n",
            "Epoch 189/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.5461 - val_accuracy: 0.8555\n",
            "Epoch 190/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5466 - val_accuracy: 0.8555\n",
            "Epoch 191/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.5472 - val_accuracy: 0.8561\n",
            "Epoch 192/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 1.5497 - val_accuracy: 0.8563\n",
            "Epoch 193/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.5616 - val_accuracy: 0.8537\n",
            "Epoch 194/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.5464 - val_accuracy: 0.8570\n",
            "Epoch 195/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 1.5823 - val_accuracy: 0.8452\n",
            "Epoch 196/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 1.5593 - val_accuracy: 0.8472\n",
            "Epoch 197/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 1.5511 - val_accuracy: 0.8510\n",
            "Epoch 198/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 1.5602 - val_accuracy: 0.8508\n",
            "Epoch 199/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 1.5460 - val_accuracy: 0.8559\n",
            "Epoch 200/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.5597 - val_accuracy: 0.8550\n",
            "Epoch 201/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.5528 - val_accuracy: 0.8539\n",
            "Epoch 202/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5576 - val_accuracy: 0.8552\n",
            "Epoch 203/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.5611 - val_accuracy: 0.8541\n",
            "Epoch 204/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.5643 - val_accuracy: 0.8550\n",
            "Epoch 205/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.5663 - val_accuracy: 0.8539\n",
            "Epoch 206/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.5695 - val_accuracy: 0.8546\n",
            "Epoch 207/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.5706 - val_accuracy: 0.8548\n",
            "Epoch 208/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.5715 - val_accuracy: 0.8557\n",
            "Epoch 209/500\n",
            "130/130 [==============================] - 4s 35ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.5711 - val_accuracy: 0.8552\n",
            "Epoch 210/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.5748 - val_accuracy: 0.8548\n",
            "Epoch 211/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.5724 - val_accuracy: 0.8552\n",
            "Epoch 212/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.5772 - val_accuracy: 0.8561\n",
            "Epoch 213/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.5796 - val_accuracy: 0.8548\n",
            "Epoch 214/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.5851 - val_accuracy: 0.8535\n",
            "Epoch 215/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.5827 - val_accuracy: 0.8543\n",
            "Epoch 216/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 1.5824 - val_accuracy: 0.8541\n",
            "Epoch 217/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 1.5853 - val_accuracy: 0.8543\n",
            "Epoch 218/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.5852 - val_accuracy: 0.8541\n",
            "Epoch 219/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.5897 - val_accuracy: 0.8543\n",
            "Epoch 220/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.5918 - val_accuracy: 0.8537\n",
            "Epoch 221/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.5840 - val_accuracy: 0.8535\n",
            "Epoch 222/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 1.6435 - val_accuracy: 0.8341\n",
            "Epoch 223/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 1.6136 - val_accuracy: 0.8503\n",
            "Epoch 224/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.5689 - val_accuracy: 0.8563\n",
            "Epoch 225/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 1.5844 - val_accuracy: 0.8575\n",
            "Epoch 226/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.5904 - val_accuracy: 0.8566\n",
            "Epoch 227/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 1.5906 - val_accuracy: 0.8550\n",
            "Epoch 228/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.5912 - val_accuracy: 0.8548\n",
            "Epoch 229/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.5947 - val_accuracy: 0.8548\n",
            "Epoch 230/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.5994 - val_accuracy: 0.8552\n",
            "Epoch 231/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 1.5988 - val_accuracy: 0.8550\n",
            "Epoch 232/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.6026 - val_accuracy: 0.8559\n",
            "Epoch 233/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.6024 - val_accuracy: 0.8566\n",
            "Epoch 234/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.6041 - val_accuracy: 0.8563\n",
            "Epoch 235/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.6095 - val_accuracy: 0.8552\n",
            "Epoch 236/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6070 - val_accuracy: 0.8563\n",
            "Epoch 237/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.6114 - val_accuracy: 0.8557\n",
            "Epoch 238/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.6091 - val_accuracy: 0.8555\n",
            "Epoch 239/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6100 - val_accuracy: 0.8566\n",
            "Epoch 240/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.6140 - val_accuracy: 0.8557\n",
            "Epoch 241/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6160 - val_accuracy: 0.8555\n",
            "Epoch 242/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.6194 - val_accuracy: 0.8575\n",
            "Epoch 243/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.6137 - val_accuracy: 0.8572\n",
            "Epoch 244/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.6154 - val_accuracy: 0.8561\n",
            "Epoch 245/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 1.6176 - val_accuracy: 0.8563\n",
            "Epoch 246/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.6177 - val_accuracy: 0.8568\n",
            "Epoch 247/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6224 - val_accuracy: 0.8566\n",
            "Epoch 248/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0025 - accuracy: 0.9986 - val_loss: 1.6211 - val_accuracy: 0.8568\n",
            "Epoch 249/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6228 - val_accuracy: 0.8579\n",
            "Epoch 250/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6267 - val_accuracy: 0.8570\n",
            "Epoch 251/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.6281 - val_accuracy: 0.8563\n",
            "Epoch 252/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6274 - val_accuracy: 0.8566\n",
            "Epoch 253/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.6301 - val_accuracy: 0.8579\n",
            "Epoch 254/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 1.6666 - val_accuracy: 0.8446\n",
            "Epoch 255/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 1.6191 - val_accuracy: 0.8537\n",
            "Epoch 256/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 1.6219 - val_accuracy: 0.8526\n",
            "Epoch 257/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 1.6324 - val_accuracy: 0.8546\n",
            "Epoch 258/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.6298 - val_accuracy: 0.8557\n",
            "Epoch 259/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.6277 - val_accuracy: 0.8568\n",
            "Epoch 260/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.6327 - val_accuracy: 0.8559\n",
            "Epoch 261/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.6302 - val_accuracy: 0.8557\n",
            "Epoch 262/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.6314 - val_accuracy: 0.8563\n",
            "Epoch 263/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 1.6322 - val_accuracy: 0.8552\n",
            "Epoch 264/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6338 - val_accuracy: 0.8557\n",
            "Epoch 265/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.6339 - val_accuracy: 0.8548\n",
            "Epoch 266/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6345 - val_accuracy: 0.8559\n",
            "Epoch 267/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.6372 - val_accuracy: 0.8552\n",
            "Epoch 268/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6353 - val_accuracy: 0.8563\n",
            "Epoch 269/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6362 - val_accuracy: 0.8555\n",
            "Epoch 270/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6374 - val_accuracy: 0.8541\n",
            "Epoch 271/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6409 - val_accuracy: 0.8557\n",
            "Epoch 272/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6392 - val_accuracy: 0.8546\n",
            "Epoch 273/500\n",
            "130/130 [==============================] - 5s 38ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6389 - val_accuracy: 0.8546\n",
            "Epoch 274/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.6428 - val_accuracy: 0.8548\n",
            "Epoch 275/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.6430 - val_accuracy: 0.8546\n",
            "Epoch 276/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6448 - val_accuracy: 0.8555\n",
            "Epoch 277/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6418 - val_accuracy: 0.8555\n",
            "Epoch 278/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6454 - val_accuracy: 0.8561\n",
            "Epoch 279/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6469 - val_accuracy: 0.8563\n",
            "Epoch 280/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.6464 - val_accuracy: 0.8563\n",
            "Epoch 281/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.6482 - val_accuracy: 0.8552\n",
            "Epoch 282/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.6439 - val_accuracy: 0.8546\n",
            "Epoch 283/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6458 - val_accuracy: 0.8557\n",
            "Epoch 284/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.6467 - val_accuracy: 0.8557\n",
            "Epoch 285/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6529 - val_accuracy: 0.8561\n",
            "Epoch 286/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.6492 - val_accuracy: 0.8563\n",
            "Epoch 287/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 1.6511 - val_accuracy: 0.8557\n",
            "Epoch 288/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.6538 - val_accuracy: 0.8543\n",
            "Epoch 289/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.6588 - val_accuracy: 0.8566\n",
            "Epoch 290/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6580 - val_accuracy: 0.8557\n",
            "Epoch 291/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.6623 - val_accuracy: 0.8563\n",
            "Epoch 292/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 1.6651 - val_accuracy: 0.8555\n",
            "Epoch 293/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6582 - val_accuracy: 0.8555\n",
            "Epoch 294/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.6668 - val_accuracy: 0.8563\n",
            "Epoch 295/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6782 - val_accuracy: 0.8548\n",
            "Epoch 296/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0536 - accuracy: 0.9845 - val_loss: 1.7316 - val_accuracy: 0.8455\n",
            "Epoch 297/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 1.6918 - val_accuracy: 0.8492\n",
            "Epoch 298/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 1.6863 - val_accuracy: 0.8526\n",
            "Epoch 299/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.6769 - val_accuracy: 0.8548\n",
            "Epoch 300/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 1.6825 - val_accuracy: 0.8526\n",
            "Epoch 301/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.6864 - val_accuracy: 0.8546\n",
            "Epoch 302/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.6868 - val_accuracy: 0.8539\n",
            "Epoch 303/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.6885 - val_accuracy: 0.8541\n",
            "Epoch 304/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6902 - val_accuracy: 0.8539\n",
            "Epoch 305/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6915 - val_accuracy: 0.8537\n",
            "Epoch 306/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6924 - val_accuracy: 0.8541\n",
            "Epoch 307/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 1.6927 - val_accuracy: 0.8541\n",
            "Epoch 308/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.6968 - val_accuracy: 0.8537\n",
            "Epoch 309/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.6947 - val_accuracy: 0.8530\n",
            "Epoch 310/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.6972 - val_accuracy: 0.8528\n",
            "Epoch 311/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.6979 - val_accuracy: 0.8530\n",
            "Epoch 312/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.6974 - val_accuracy: 0.8521\n",
            "Epoch 313/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 1.6921 - val_accuracy: 0.8535\n",
            "Epoch 314/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.6933 - val_accuracy: 0.8535\n",
            "Epoch 315/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.6948 - val_accuracy: 0.8535\n",
            "Epoch 316/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7002 - val_accuracy: 0.8543\n",
            "Epoch 317/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.7000 - val_accuracy: 0.8539\n",
            "Epoch 318/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7015 - val_accuracy: 0.8539\n",
            "Epoch 319/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.7025 - val_accuracy: 0.8535\n",
            "Epoch 320/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.7029 - val_accuracy: 0.8535\n",
            "Epoch 321/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7044 - val_accuracy: 0.8535\n",
            "Epoch 322/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.7055 - val_accuracy: 0.8523\n",
            "Epoch 323/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.7051 - val_accuracy: 0.8521\n",
            "Epoch 324/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7066 - val_accuracy: 0.8535\n",
            "Epoch 325/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7069 - val_accuracy: 0.8535\n",
            "Epoch 326/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7077 - val_accuracy: 0.8541\n",
            "Epoch 327/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7067 - val_accuracy: 0.8537\n",
            "Epoch 328/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7099 - val_accuracy: 0.8539\n",
            "Epoch 329/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7071 - val_accuracy: 0.8555\n",
            "Epoch 330/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7128 - val_accuracy: 0.8537\n",
            "Epoch 331/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7112 - val_accuracy: 0.8537\n",
            "Epoch 332/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.7158 - val_accuracy: 0.8535\n",
            "Epoch 333/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7152 - val_accuracy: 0.8552\n",
            "Epoch 334/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.7165 - val_accuracy: 0.8537\n",
            "Epoch 335/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7150 - val_accuracy: 0.8552\n",
            "Epoch 336/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 1.7895 - val_accuracy: 0.8366\n",
            "Epoch 337/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 1.8105 - val_accuracy: 0.8379\n",
            "Epoch 338/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 1.6857 - val_accuracy: 0.8517\n",
            "Epoch 339/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.6907 - val_accuracy: 0.8521\n",
            "Epoch 340/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 1.6852 - val_accuracy: 0.8546\n",
            "Epoch 341/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 1.6883 - val_accuracy: 0.8555\n",
            "Epoch 342/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.6932 - val_accuracy: 0.8548\n",
            "Epoch 343/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6945 - val_accuracy: 0.8557\n",
            "Epoch 344/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.6982 - val_accuracy: 0.8546\n",
            "Epoch 345/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.6983 - val_accuracy: 0.8563\n",
            "Epoch 346/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.7016 - val_accuracy: 0.8563\n",
            "Epoch 347/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7041 - val_accuracy: 0.8557\n",
            "Epoch 348/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7051 - val_accuracy: 0.8557\n",
            "Epoch 349/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7079 - val_accuracy: 0.8550\n",
            "Epoch 350/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7096 - val_accuracy: 0.8546\n",
            "Epoch 351/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7125 - val_accuracy: 0.8548\n",
            "Epoch 352/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7123 - val_accuracy: 0.8555\n",
            "Epoch 353/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7150 - val_accuracy: 0.8557\n",
            "Epoch 354/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.7183 - val_accuracy: 0.8552\n",
            "Epoch 355/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7194 - val_accuracy: 0.8555\n",
            "Epoch 356/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7210 - val_accuracy: 0.8543\n",
            "Epoch 357/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 1.7245 - val_accuracy: 0.8539\n",
            "Epoch 358/500\n",
            "130/130 [==============================] - 4s 27ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7256 - val_accuracy: 0.8543\n",
            "Epoch 359/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7259 - val_accuracy: 0.8548\n",
            "Epoch 360/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7287 - val_accuracy: 0.8550\n",
            "Epoch 361/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7319 - val_accuracy: 0.8543\n",
            "Epoch 362/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7314 - val_accuracy: 0.8566\n",
            "Epoch 363/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7349 - val_accuracy: 0.8548\n",
            "Epoch 364/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7361 - val_accuracy: 0.8552\n",
            "Epoch 365/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7400 - val_accuracy: 0.8548\n",
            "Epoch 366/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.7421 - val_accuracy: 0.8561\n",
            "Epoch 367/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7415 - val_accuracy: 0.8532\n",
            "Epoch 368/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.7437 - val_accuracy: 0.8552\n",
            "Epoch 369/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7420 - val_accuracy: 0.8550\n",
            "Epoch 370/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7479 - val_accuracy: 0.8555\n",
            "Epoch 371/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7519 - val_accuracy: 0.8546\n",
            "Epoch 372/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7512 - val_accuracy: 0.8541\n",
            "Epoch 373/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.7525 - val_accuracy: 0.8546\n",
            "Epoch 374/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.7559 - val_accuracy: 0.8546\n",
            "Epoch 375/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7558 - val_accuracy: 0.8541\n",
            "Epoch 376/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7596 - val_accuracy: 0.8541\n",
            "Epoch 377/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7596 - val_accuracy: 0.8550\n",
            "Epoch 378/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.7528 - val_accuracy: 0.8555\n",
            "Epoch 379/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 1.7774 - val_accuracy: 0.8446\n",
            "Epoch 380/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.7766 - val_accuracy: 0.8468\n",
            "Epoch 381/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 1.7550 - val_accuracy: 0.8495\n",
            "Epoch 382/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 1.7608 - val_accuracy: 0.8508\n",
            "Epoch 383/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.7533 - val_accuracy: 0.8506\n",
            "Epoch 384/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.7541 - val_accuracy: 0.8515\n",
            "Epoch 385/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7579 - val_accuracy: 0.8517\n",
            "Epoch 386/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7604 - val_accuracy: 0.8510\n",
            "Epoch 387/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7624 - val_accuracy: 0.8515\n",
            "Epoch 388/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7617 - val_accuracy: 0.8512\n",
            "Epoch 389/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7646 - val_accuracy: 0.8519\n",
            "Epoch 390/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7658 - val_accuracy: 0.8510\n",
            "Epoch 391/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7664 - val_accuracy: 0.8519\n",
            "Epoch 392/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7671 - val_accuracy: 0.8528\n",
            "Epoch 393/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7696 - val_accuracy: 0.8523\n",
            "Epoch 394/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7697 - val_accuracy: 0.8528\n",
            "Epoch 395/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7716 - val_accuracy: 0.8523\n",
            "Epoch 396/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7712 - val_accuracy: 0.8532\n",
            "Epoch 397/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7708 - val_accuracy: 0.8543\n",
            "Epoch 398/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7722 - val_accuracy: 0.8541\n",
            "Epoch 399/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7753 - val_accuracy: 0.8543\n",
            "Epoch 400/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7718 - val_accuracy: 0.8552\n",
            "Epoch 401/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7756 - val_accuracy: 0.8535\n",
            "Epoch 402/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7769 - val_accuracy: 0.8543\n",
            "Epoch 403/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7751 - val_accuracy: 0.8539\n",
            "Epoch 404/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.7776 - val_accuracy: 0.8541\n",
            "Epoch 405/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7782 - val_accuracy: 0.8546\n",
            "Epoch 406/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7782 - val_accuracy: 0.8539\n",
            "Epoch 407/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.7859 - val_accuracy: 0.8479\n",
            "Epoch 408/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 1.7944 - val_accuracy: 0.8439\n",
            "Epoch 409/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 1.7696 - val_accuracy: 0.8495\n",
            "Epoch 410/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.7614 - val_accuracy: 0.8512\n",
            "Epoch 411/500\n",
            "130/130 [==============================] - 4s 35ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 1.7630 - val_accuracy: 0.8541\n",
            "Epoch 412/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.7635 - val_accuracy: 0.8546\n",
            "Epoch 413/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.7653 - val_accuracy: 0.8532\n",
            "Epoch 414/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.7660 - val_accuracy: 0.8552\n",
            "Epoch 415/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.7669 - val_accuracy: 0.8546\n",
            "Epoch 416/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.7725 - val_accuracy: 0.8541\n",
            "Epoch 417/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7727 - val_accuracy: 0.8543\n",
            "Epoch 418/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 1.7748 - val_accuracy: 0.8539\n",
            "Epoch 419/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7759 - val_accuracy: 0.8548\n",
            "Epoch 420/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7772 - val_accuracy: 0.8546\n",
            "Epoch 421/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7804 - val_accuracy: 0.8546\n",
            "Epoch 422/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7840 - val_accuracy: 0.8548\n",
            "Epoch 423/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7820 - val_accuracy: 0.8548\n",
            "Epoch 424/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7851 - val_accuracy: 0.8552\n",
            "Epoch 425/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.7863 - val_accuracy: 0.8546\n",
            "Epoch 426/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7886 - val_accuracy: 0.8543\n",
            "Epoch 427/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.7903 - val_accuracy: 0.8541\n",
            "Epoch 428/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7882 - val_accuracy: 0.8539\n",
            "Epoch 429/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7899 - val_accuracy: 0.8548\n",
            "Epoch 430/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.7919 - val_accuracy: 0.8548\n",
            "Epoch 431/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7974 - val_accuracy: 0.8552\n",
            "Epoch 432/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.7995 - val_accuracy: 0.8543\n",
            "Epoch 433/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7958 - val_accuracy: 0.8552\n",
            "Epoch 434/500\n",
            "130/130 [==============================] - 5s 36ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.8022 - val_accuracy: 0.8535\n",
            "Epoch 435/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7991 - val_accuracy: 0.8552\n",
            "Epoch 436/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7975 - val_accuracy: 0.8550\n",
            "Epoch 437/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.8050 - val_accuracy: 0.8555\n",
            "Epoch 438/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.8046 - val_accuracy: 0.8546\n",
            "Epoch 439/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.8046 - val_accuracy: 0.8548\n",
            "Epoch 440/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.8027 - val_accuracy: 0.8541\n",
            "Epoch 441/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.8017 - val_accuracy: 0.8548\n",
            "Epoch 442/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8027 - val_accuracy: 0.8552\n",
            "Epoch 443/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.8077 - val_accuracy: 0.8548\n",
            "Epoch 444/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.8065 - val_accuracy: 0.8543\n",
            "Epoch 445/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.8074 - val_accuracy: 0.8539\n",
            "Epoch 446/500\n",
            "130/130 [==============================] - 4s 34ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.8073 - val_accuracy: 0.8546\n",
            "Epoch 447/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.8008 - val_accuracy: 0.8568\n",
            "Epoch 448/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.8448 - val_accuracy: 0.8392\n",
            "Epoch 449/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 1.7843 - val_accuracy: 0.8459\n",
            "Epoch 450/500\n",
            "130/130 [==============================] - 4s 29ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 1.7820 - val_accuracy: 0.8523\n",
            "Epoch 451/500\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 1.7737 - val_accuracy: 0.8563\n",
            "Epoch 452/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 1.7759 - val_accuracy: 0.8572\n",
            "Epoch 453/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.7732 - val_accuracy: 0.8570\n",
            "Epoch 454/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.7762 - val_accuracy: 0.8575\n",
            "Epoch 455/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.7765 - val_accuracy: 0.8570\n",
            "Epoch 456/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7801 - val_accuracy: 0.8561\n",
            "Epoch 457/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7824 - val_accuracy: 0.8561\n",
            "Epoch 458/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7818 - val_accuracy: 0.8566\n",
            "Epoch 459/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7844 - val_accuracy: 0.8563\n",
            "Epoch 460/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.7879 - val_accuracy: 0.8552\n",
            "Epoch 461/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7861 - val_accuracy: 0.8552\n",
            "Epoch 462/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7891 - val_accuracy: 0.8563\n",
            "Epoch 463/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.7899 - val_accuracy: 0.8561\n",
            "Epoch 464/500\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7926 - val_accuracy: 0.8557\n",
            "Epoch 465/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7903 - val_accuracy: 0.8566\n",
            "Epoch 466/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 1.7924 - val_accuracy: 0.8563\n",
            "Epoch 467/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.7950 - val_accuracy: 0.8575\n",
            "Epoch 468/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.7988 - val_accuracy: 0.8577\n",
            "Epoch 469/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.7947 - val_accuracy: 0.8572\n",
            "Epoch 470/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.7976 - val_accuracy: 0.8559\n",
            "Epoch 471/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7988 - val_accuracy: 0.8563\n",
            "Epoch 472/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.7958 - val_accuracy: 0.8579\n",
            "Epoch 473/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.7982 - val_accuracy: 0.8575\n",
            "Epoch 474/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7989 - val_accuracy: 0.8579\n",
            "Epoch 475/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8026 - val_accuracy: 0.8581\n",
            "Epoch 476/500\n",
            "130/130 [==============================] - 4s 32ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.8024 - val_accuracy: 0.8586\n",
            "Epoch 477/500\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 1.8033 - val_accuracy: 0.8575\n",
            "Epoch 478/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.8044 - val_accuracy: 0.8572\n",
            "Epoch 479/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.8087 - val_accuracy: 0.8575\n",
            "Epoch 480/500\n",
            "130/130 [==============================] - 3s 27ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.8076 - val_accuracy: 0.8579\n",
            "Epoch 481/500\n",
            "130/130 [==============================] - 4s 30ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.8082 - val_accuracy: 0.8570\n",
            "Epoch 482/500\n",
            "130/130 [==============================] - 3s 23ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.8101 - val_accuracy: 0.8575\n",
            "Epoch 483/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.8092 - val_accuracy: 0.8570\n",
            "Epoch 484/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.8108 - val_accuracy: 0.8572\n",
            "Epoch 485/500\n",
            "130/130 [==============================] - 5s 37ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.8121 - val_accuracy: 0.8568\n",
            "Epoch 486/500\n",
            "130/130 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.8173 - val_accuracy: 0.8568\n",
            "Epoch 487/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.8190 - val_accuracy: 0.8563\n",
            "Epoch 488/500\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.8159 - val_accuracy: 0.8570\n",
            "Epoch 489/500\n",
            "130/130 [==============================] - 4s 31ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.8163 - val_accuracy: 0.8572\n",
            "Epoch 490/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.8232 - val_accuracy: 0.8555\n",
            "Epoch 491/500\n",
            "130/130 [==============================] - 3s 21ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8221 - val_accuracy: 0.8572\n",
            "Epoch 492/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8234 - val_accuracy: 0.8572\n",
            "Epoch 493/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.8403 - val_accuracy: 0.8528\n",
            "Epoch 494/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 1.8620 - val_accuracy: 0.8488\n",
            "Epoch 495/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 1.8398 - val_accuracy: 0.8539\n",
            "Epoch 496/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 1.8144 - val_accuracy: 0.8537\n",
            "Epoch 497/500\n",
            "130/130 [==============================] - 5s 35ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 1.8141 - val_accuracy: 0.8548\n",
            "Epoch 498/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.8148 - val_accuracy: 0.8546\n",
            "Epoch 499/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.8159 - val_accuracy: 0.8552\n",
            "Epoch 500/500\n",
            "130/130 [==============================] - 3s 22ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.8169 - val_accuracy: 0.8550\n",
            "Training accuracy 99.89%\n",
            "\n",
            "Current batch size: 16\n",
            "Epoch 1/500\n",
            "65/65 [==============================] - 26s 200ms/step - loss: 6.0832 - accuracy: 0.0405 - val_loss: 5.7991 - val_accuracy: 0.0543\n",
            "Epoch 2/500\n",
            "65/65 [==============================] - 7s 106ms/step - loss: 5.5503 - accuracy: 0.0694 - val_loss: 5.4885 - val_accuracy: 0.0881\n",
            "Epoch 3/500\n",
            "65/65 [==============================] - 4s 55ms/step - loss: 5.1462 - accuracy: 0.0989 - val_loss: 5.1073 - val_accuracy: 0.1090\n",
            "Epoch 4/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 4.7199 - accuracy: 0.1686 - val_loss: 4.6822 - val_accuracy: 0.1941\n",
            "Epoch 5/500\n",
            "65/65 [==============================] - 3s 54ms/step - loss: 4.2376 - accuracy: 0.2277 - val_loss: 4.2587 - val_accuracy: 0.2397\n",
            "Epoch 6/500\n",
            "65/65 [==============================] - 3s 51ms/step - loss: 3.8197 - accuracy: 0.2901 - val_loss: 3.9157 - val_accuracy: 0.2955\n",
            "Epoch 7/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 3.4402 - accuracy: 0.3443 - val_loss: 3.5834 - val_accuracy: 0.3382\n",
            "Epoch 8/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 3.1152 - accuracy: 0.4001 - val_loss: 3.2834 - val_accuracy: 0.3889\n",
            "Epoch 9/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 2.8049 - accuracy: 0.4513 - val_loss: 3.0143 - val_accuracy: 0.4276\n",
            "Epoch 10/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 2.5273 - accuracy: 0.4992 - val_loss: 2.7874 - val_accuracy: 0.4696\n",
            "Epoch 11/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 2.2940 - accuracy: 0.5452 - val_loss: 2.5672 - val_accuracy: 0.5112\n",
            "Epoch 12/500\n",
            "65/65 [==============================] - 3s 46ms/step - loss: 2.0764 - accuracy: 0.5839 - val_loss: 2.3622 - val_accuracy: 0.5533\n",
            "Epoch 13/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 1.9003 - accuracy: 0.6208 - val_loss: 2.2036 - val_accuracy: 0.5811\n",
            "Epoch 14/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 1.7316 - accuracy: 0.6501 - val_loss: 2.0644 - val_accuracy: 0.6071\n",
            "Epoch 15/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 1.5946 - accuracy: 0.6776 - val_loss: 1.9291 - val_accuracy: 0.6398\n",
            "Epoch 16/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 1.4685 - accuracy: 0.7042 - val_loss: 1.8305 - val_accuracy: 0.6600\n",
            "Epoch 17/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 1.3565 - accuracy: 0.7235 - val_loss: 1.7432 - val_accuracy: 0.6818\n",
            "Epoch 18/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 1.2532 - accuracy: 0.7466 - val_loss: 1.6587 - val_accuracy: 0.6965\n",
            "Epoch 19/500\n",
            "65/65 [==============================] - 3s 44ms/step - loss: 1.1645 - accuracy: 0.7648 - val_loss: 1.5957 - val_accuracy: 0.7136\n",
            "Epoch 20/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 1.0821 - accuracy: 0.7810 - val_loss: 1.5365 - val_accuracy: 0.7269\n",
            "Epoch 21/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 1.0115 - accuracy: 0.7952 - val_loss: 1.4831 - val_accuracy: 0.7349\n",
            "Epoch 22/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.9406 - accuracy: 0.8071 - val_loss: 1.4420 - val_accuracy: 0.7498\n",
            "Epoch 23/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.8826 - accuracy: 0.8200 - val_loss: 1.3922 - val_accuracy: 0.7594\n",
            "Epoch 24/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.8320 - accuracy: 0.8309 - val_loss: 1.3499 - val_accuracy: 0.7676\n",
            "Epoch 25/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.7779 - accuracy: 0.8430 - val_loss: 1.3206 - val_accuracy: 0.7714\n",
            "Epoch 26/500\n",
            "65/65 [==============================] - 3s 42ms/step - loss: 0.7312 - accuracy: 0.8526 - val_loss: 1.2886 - val_accuracy: 0.7752\n",
            "Epoch 27/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.6821 - accuracy: 0.8638 - val_loss: 1.2699 - val_accuracy: 0.7812\n",
            "Epoch 28/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.6457 - accuracy: 0.8708 - val_loss: 1.2367 - val_accuracy: 0.7890\n",
            "Epoch 29/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.6063 - accuracy: 0.8797 - val_loss: 1.2131 - val_accuracy: 0.7996\n",
            "Epoch 30/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.5702 - accuracy: 0.8871 - val_loss: 1.2020 - val_accuracy: 0.7976\n",
            "Epoch 31/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.5387 - accuracy: 0.8928 - val_loss: 1.1833 - val_accuracy: 0.8001\n",
            "Epoch 32/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.5124 - accuracy: 0.9003 - val_loss: 1.1637 - val_accuracy: 0.8061\n",
            "Epoch 33/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.4827 - accuracy: 0.9057 - val_loss: 1.1515 - val_accuracy: 0.8079\n",
            "Epoch 34/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.4507 - accuracy: 0.9125 - val_loss: 1.1290 - val_accuracy: 0.8137\n",
            "Epoch 35/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.4255 - accuracy: 0.9171 - val_loss: 1.1159 - val_accuracy: 0.8188\n",
            "Epoch 36/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.4031 - accuracy: 0.9202 - val_loss: 1.1127 - val_accuracy: 0.8159\n",
            "Epoch 37/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.3869 - accuracy: 0.9261 - val_loss: 1.1038 - val_accuracy: 0.8205\n",
            "Epoch 38/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.3737 - accuracy: 0.9287 - val_loss: 1.1153 - val_accuracy: 0.8179\n",
            "Epoch 39/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.3569 - accuracy: 0.9309 - val_loss: 1.0932 - val_accuracy: 0.8228\n",
            "Epoch 40/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.3311 - accuracy: 0.9362 - val_loss: 1.0768 - val_accuracy: 0.8312\n",
            "Epoch 41/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.3108 - accuracy: 0.9397 - val_loss: 1.0764 - val_accuracy: 0.8299\n",
            "Epoch 42/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.2927 - accuracy: 0.9437 - val_loss: 1.0590 - val_accuracy: 0.8350\n",
            "Epoch 43/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.2765 - accuracy: 0.9465 - val_loss: 1.0577 - val_accuracy: 0.8368\n",
            "Epoch 44/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.2641 - accuracy: 0.9499 - val_loss: 1.0578 - val_accuracy: 0.8361\n",
            "Epoch 45/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.2544 - accuracy: 0.9520 - val_loss: 1.0504 - val_accuracy: 0.8337\n",
            "Epoch 46/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.2402 - accuracy: 0.9549 - val_loss: 1.0539 - val_accuracy: 0.8361\n",
            "Epoch 47/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.2305 - accuracy: 0.9570 - val_loss: 1.0592 - val_accuracy: 0.8352\n",
            "Epoch 48/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.2180 - accuracy: 0.9581 - val_loss: 1.0521 - val_accuracy: 0.8348\n",
            "Epoch 49/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.2092 - accuracy: 0.9614 - val_loss: 1.0490 - val_accuracy: 0.8379\n",
            "Epoch 50/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1988 - accuracy: 0.9627 - val_loss: 1.0553 - val_accuracy: 0.8346\n",
            "Epoch 51/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1901 - accuracy: 0.9644 - val_loss: 1.0586 - val_accuracy: 0.8363\n",
            "Epoch 52/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.1829 - accuracy: 0.9663 - val_loss: 1.0548 - val_accuracy: 0.8394\n",
            "Epoch 53/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.1720 - accuracy: 0.9683 - val_loss: 1.0509 - val_accuracy: 0.8368\n",
            "Epoch 54/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.1643 - accuracy: 0.9698 - val_loss: 1.0550 - val_accuracy: 0.8372\n",
            "Epoch 55/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1591 - accuracy: 0.9713 - val_loss: 1.0567 - val_accuracy: 0.8406\n",
            "Epoch 56/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.1519 - accuracy: 0.9723 - val_loss: 1.0611 - val_accuracy: 0.8370\n",
            "Epoch 57/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.1441 - accuracy: 0.9737 - val_loss: 1.0596 - val_accuracy: 0.8421\n",
            "Epoch 58/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.1377 - accuracy: 0.9755 - val_loss: 1.0456 - val_accuracy: 0.8446\n",
            "Epoch 59/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.1642 - accuracy: 0.9682 - val_loss: 1.0492 - val_accuracy: 0.8432\n",
            "Epoch 60/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1374 - accuracy: 0.9740 - val_loss: 1.0476 - val_accuracy: 0.8435\n",
            "Epoch 61/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.1250 - accuracy: 0.9777 - val_loss: 1.0506 - val_accuracy: 0.8423\n",
            "Epoch 62/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.1158 - accuracy: 0.9801 - val_loss: 1.0584 - val_accuracy: 0.8452\n",
            "Epoch 63/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.1100 - accuracy: 0.9813 - val_loss: 1.0522 - val_accuracy: 0.8455\n",
            "Epoch 64/500\n",
            "65/65 [==============================] - 3s 42ms/step - loss: 0.1046 - accuracy: 0.9824 - val_loss: 1.0580 - val_accuracy: 0.8446\n",
            "Epoch 65/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0997 - accuracy: 0.9834 - val_loss: 1.0667 - val_accuracy: 0.8457\n",
            "Epoch 66/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0945 - accuracy: 0.9843 - val_loss: 1.0746 - val_accuracy: 0.8419\n",
            "Epoch 67/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0908 - accuracy: 0.9849 - val_loss: 1.0652 - val_accuracy: 0.8446\n",
            "Epoch 68/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0860 - accuracy: 0.9861 - val_loss: 1.0743 - val_accuracy: 0.8408\n",
            "Epoch 69/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0825 - accuracy: 0.9870 - val_loss: 1.0886 - val_accuracy: 0.8430\n",
            "Epoch 70/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0790 - accuracy: 0.9872 - val_loss: 1.0832 - val_accuracy: 0.8426\n",
            "Epoch 71/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0769 - accuracy: 0.9876 - val_loss: 1.0955 - val_accuracy: 0.8432\n",
            "Epoch 72/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0755 - accuracy: 0.9882 - val_loss: 1.0947 - val_accuracy: 0.8432\n",
            "Epoch 73/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0707 - accuracy: 0.9888 - val_loss: 1.0880 - val_accuracy: 0.8432\n",
            "Epoch 74/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0693 - accuracy: 0.9892 - val_loss: 1.0902 - val_accuracy: 0.8428\n",
            "Epoch 75/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0675 - accuracy: 0.9891 - val_loss: 1.0964 - val_accuracy: 0.8401\n",
            "Epoch 76/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0645 - accuracy: 0.9900 - val_loss: 1.0969 - val_accuracy: 0.8441\n",
            "Epoch 77/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0606 - accuracy: 0.9907 - val_loss: 1.0965 - val_accuracy: 0.8423\n",
            "Epoch 78/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0582 - accuracy: 0.9914 - val_loss: 1.1025 - val_accuracy: 0.8430\n",
            "Epoch 79/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0557 - accuracy: 0.9918 - val_loss: 1.1159 - val_accuracy: 0.8428\n",
            "Epoch 80/500\n",
            "65/65 [==============================] - 3s 42ms/step - loss: 0.0578 - accuracy: 0.9909 - val_loss: 1.1214 - val_accuracy: 0.8408\n",
            "Epoch 81/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0546 - accuracy: 0.9915 - val_loss: 1.1032 - val_accuracy: 0.8450\n",
            "Epoch 82/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0502 - accuracy: 0.9921 - val_loss: 1.1083 - val_accuracy: 0.8439\n",
            "Epoch 83/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0484 - accuracy: 0.9927 - val_loss: 1.1152 - val_accuracy: 0.8426\n",
            "Epoch 84/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0495 - accuracy: 0.9921 - val_loss: 1.1186 - val_accuracy: 0.8450\n",
            "Epoch 85/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0477 - accuracy: 0.9928 - val_loss: 1.1204 - val_accuracy: 0.8455\n",
            "Epoch 86/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0434 - accuracy: 0.9938 - val_loss: 1.1301 - val_accuracy: 0.8448\n",
            "Epoch 87/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0415 - accuracy: 0.9938 - val_loss: 1.1412 - val_accuracy: 0.8426\n",
            "Epoch 88/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0394 - accuracy: 0.9943 - val_loss: 1.1288 - val_accuracy: 0.8455\n",
            "Epoch 89/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0379 - accuracy: 0.9945 - val_loss: 1.1482 - val_accuracy: 0.8394\n",
            "Epoch 90/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0379 - accuracy: 0.9944 - val_loss: 1.1411 - val_accuracy: 0.8441\n",
            "Epoch 91/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0362 - accuracy: 0.9947 - val_loss: 1.1504 - val_accuracy: 0.8435\n",
            "Epoch 92/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0342 - accuracy: 0.9948 - val_loss: 1.1494 - val_accuracy: 0.8426\n",
            "Epoch 93/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0328 - accuracy: 0.9949 - val_loss: 1.1550 - val_accuracy: 0.8417\n",
            "Epoch 94/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0312 - accuracy: 0.9954 - val_loss: 1.1606 - val_accuracy: 0.8408\n",
            "Epoch 95/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0315 - accuracy: 0.9951 - val_loss: 1.1583 - val_accuracy: 0.8435\n",
            "Epoch 96/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0312 - accuracy: 0.9955 - val_loss: 1.1729 - val_accuracy: 0.8430\n",
            "Epoch 97/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0322 - accuracy: 0.9947 - val_loss: 1.1485 - val_accuracy: 0.8441\n",
            "Epoch 98/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0313 - accuracy: 0.9956 - val_loss: 1.1658 - val_accuracy: 0.8441\n",
            "Epoch 99/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0293 - accuracy: 0.9955 - val_loss: 1.1719 - val_accuracy: 0.8430\n",
            "Epoch 100/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0301 - accuracy: 0.9951 - val_loss: 1.1984 - val_accuracy: 0.8372\n",
            "Epoch 101/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0274 - accuracy: 0.9958 - val_loss: 1.1788 - val_accuracy: 0.8386\n",
            "Epoch 102/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0251 - accuracy: 0.9961 - val_loss: 1.1756 - val_accuracy: 0.8421\n",
            "Epoch 103/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0251 - accuracy: 0.9961 - val_loss: 1.1767 - val_accuracy: 0.8435\n",
            "Epoch 104/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0263 - accuracy: 0.9959 - val_loss: 1.1888 - val_accuracy: 0.8417\n",
            "Epoch 105/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0244 - accuracy: 0.9964 - val_loss: 1.1857 - val_accuracy: 0.8435\n",
            "Epoch 106/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0216 - accuracy: 0.9967 - val_loss: 1.1943 - val_accuracy: 0.8419\n",
            "Epoch 107/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 1.1915 - val_accuracy: 0.8401\n",
            "Epoch 108/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0199 - accuracy: 0.9971 - val_loss: 1.1934 - val_accuracy: 0.8421\n",
            "Epoch 109/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0187 - accuracy: 0.9970 - val_loss: 1.1935 - val_accuracy: 0.8421\n",
            "Epoch 110/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0182 - accuracy: 0.9971 - val_loss: 1.1906 - val_accuracy: 0.8421\n",
            "Epoch 111/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 1.2109 - val_accuracy: 0.8386\n",
            "Epoch 112/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 1.2082 - val_accuracy: 0.8443\n",
            "Epoch 113/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 1.2027 - val_accuracy: 0.8439\n",
            "Epoch 114/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 1.2117 - val_accuracy: 0.8390\n",
            "Epoch 115/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 1.2247 - val_accuracy: 0.8437\n",
            "Epoch 116/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0284 - accuracy: 0.9948 - val_loss: 1.2245 - val_accuracy: 0.8408\n",
            "Epoch 117/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0332 - accuracy: 0.9931 - val_loss: 1.2221 - val_accuracy: 0.8435\n",
            "Epoch 118/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0342 - accuracy: 0.9937 - val_loss: 1.1967 - val_accuracy: 0.8435\n",
            "Epoch 119/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0343 - accuracy: 0.9935 - val_loss: 1.1849 - val_accuracy: 0.8443\n",
            "Epoch 120/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0249 - accuracy: 0.9958 - val_loss: 1.2019 - val_accuracy: 0.8477\n",
            "Epoch 121/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 1.1981 - val_accuracy: 0.8481\n",
            "Epoch 122/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 1.1934 - val_accuracy: 0.8466\n",
            "Epoch 123/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0137 - accuracy: 0.9973 - val_loss: 1.2043 - val_accuracy: 0.8470\n",
            "Epoch 124/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 1.2057 - val_accuracy: 0.8472\n",
            "Epoch 125/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 1.2211 - val_accuracy: 0.8481\n",
            "Epoch 126/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 1.2167 - val_accuracy: 0.8466\n",
            "Epoch 127/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 1.2214 - val_accuracy: 0.8461\n",
            "Epoch 128/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 1.2209 - val_accuracy: 0.8483\n",
            "Epoch 129/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 1.2273 - val_accuracy: 0.8470\n",
            "Epoch 130/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 1.2287 - val_accuracy: 0.8468\n",
            "Epoch 131/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 1.2346 - val_accuracy: 0.8468\n",
            "Epoch 132/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 1.2296 - val_accuracy: 0.8490\n",
            "Epoch 133/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 1.2447 - val_accuracy: 0.8461\n",
            "Epoch 134/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 1.2418 - val_accuracy: 0.8475\n",
            "Epoch 135/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 1.2492 - val_accuracy: 0.8479\n",
            "Epoch 136/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 1.2568 - val_accuracy: 0.8457\n",
            "Epoch 137/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 1.2736 - val_accuracy: 0.8448\n",
            "Epoch 138/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 1.2783 - val_accuracy: 0.8381\n",
            "Epoch 139/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 1.2380 - val_accuracy: 0.8457\n",
            "Epoch 140/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0243 - accuracy: 0.9946 - val_loss: 1.2488 - val_accuracy: 0.8483\n",
            "Epoch 141/500\n",
            "65/65 [==============================] - 3s 38ms/step - loss: 0.0199 - accuracy: 0.9957 - val_loss: 1.2492 - val_accuracy: 0.8483\n",
            "Epoch 142/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 1.2557 - val_accuracy: 0.8506\n",
            "Epoch 143/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 1.2462 - val_accuracy: 0.8495\n",
            "Epoch 144/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 1.2488 - val_accuracy: 0.8519\n",
            "Epoch 145/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 1.2621 - val_accuracy: 0.8517\n",
            "Epoch 146/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 1.2625 - val_accuracy: 0.8521\n",
            "Epoch 147/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 1.2603 - val_accuracy: 0.8517\n",
            "Epoch 148/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 1.2597 - val_accuracy: 0.8535\n",
            "Epoch 149/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 1.2775 - val_accuracy: 0.8512\n",
            "Epoch 150/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 1.2711 - val_accuracy: 0.8508\n",
            "Epoch 151/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 1.2763 - val_accuracy: 0.8517\n",
            "Epoch 152/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.2727 - val_accuracy: 0.8521\n",
            "Epoch 153/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 1.2894 - val_accuracy: 0.8497\n",
            "Epoch 154/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 1.2842 - val_accuracy: 0.8517\n",
            "Epoch 155/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 1.2827 - val_accuracy: 0.8506\n",
            "Epoch 156/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.2805 - val_accuracy: 0.8495\n",
            "Epoch 157/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.3005 - val_accuracy: 0.8519\n",
            "Epoch 158/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 1.3013 - val_accuracy: 0.8479\n",
            "Epoch 159/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 1.2942 - val_accuracy: 0.8479\n",
            "Epoch 160/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.3116 - val_accuracy: 0.8501\n",
            "Epoch 161/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 1.3182 - val_accuracy: 0.8521\n",
            "Epoch 162/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 1.3263 - val_accuracy: 0.8446\n",
            "Epoch 163/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 1.3706 - val_accuracy: 0.8290\n",
            "Epoch 164/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 1.3270 - val_accuracy: 0.8354\n",
            "Epoch 165/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0287 - accuracy: 0.9923 - val_loss: 1.3191 - val_accuracy: 0.8430\n",
            "Epoch 166/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 1.3117 - val_accuracy: 0.8477\n",
            "Epoch 167/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 1.3149 - val_accuracy: 0.8492\n",
            "Epoch 168/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 1.3384 - val_accuracy: 0.8459\n",
            "Epoch 169/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 1.3278 - val_accuracy: 0.8486\n",
            "Epoch 170/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 1.3299 - val_accuracy: 0.8501\n",
            "Epoch 171/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 1.3355 - val_accuracy: 0.8497\n",
            "Epoch 172/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 1.3346 - val_accuracy: 0.8490\n",
            "Epoch 173/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 1.3396 - val_accuracy: 0.8495\n",
            "Epoch 174/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 1.3394 - val_accuracy: 0.8483\n",
            "Epoch 175/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 1.3408 - val_accuracy: 0.8497\n",
            "Epoch 176/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.3462 - val_accuracy: 0.8488\n",
            "Epoch 177/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.3467 - val_accuracy: 0.8492\n",
            "Epoch 178/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.3517 - val_accuracy: 0.8483\n",
            "Epoch 179/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.3524 - val_accuracy: 0.8495\n",
            "Epoch 180/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.3524 - val_accuracy: 0.8481\n",
            "Epoch 181/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.3607 - val_accuracy: 0.8481\n",
            "Epoch 182/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.3452 - val_accuracy: 0.8488\n",
            "Epoch 183/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 1.3617 - val_accuracy: 0.8495\n",
            "Epoch 184/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 1.3613 - val_accuracy: 0.8468\n",
            "Epoch 185/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.3693 - val_accuracy: 0.8477\n",
            "Epoch 186/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 1.3670 - val_accuracy: 0.8488\n",
            "Epoch 187/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 1.3745 - val_accuracy: 0.8483\n",
            "Epoch 188/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.3614 - val_accuracy: 0.8512\n",
            "Epoch 189/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 1.3727 - val_accuracy: 0.8468\n",
            "Epoch 190/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 1.3739 - val_accuracy: 0.8448\n",
            "Epoch 191/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 1.3778 - val_accuracy: 0.8448\n",
            "Epoch 192/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.3913 - val_accuracy: 0.8437\n",
            "Epoch 193/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 1.3556 - val_accuracy: 0.8481\n",
            "Epoch 194/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 1.3888 - val_accuracy: 0.8437\n",
            "Epoch 195/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 1.3931 - val_accuracy: 0.8432\n",
            "Epoch 196/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 1.3669 - val_accuracy: 0.8468\n",
            "Epoch 197/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 1.3671 - val_accuracy: 0.8492\n",
            "Epoch 198/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 1.3626 - val_accuracy: 0.8506\n",
            "Epoch 199/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 1.3726 - val_accuracy: 0.8499\n",
            "Epoch 200/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.3802 - val_accuracy: 0.8488\n",
            "Epoch 201/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 1.3776 - val_accuracy: 0.8499\n",
            "Epoch 202/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.3775 - val_accuracy: 0.8508\n",
            "Epoch 203/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.3820 - val_accuracy: 0.8495\n",
            "Epoch 204/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.3854 - val_accuracy: 0.8499\n",
            "Epoch 205/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.3825 - val_accuracy: 0.8497\n",
            "Epoch 206/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.3849 - val_accuracy: 0.8503\n",
            "Epoch 207/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 1.3880 - val_accuracy: 0.8501\n",
            "Epoch 208/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.3890 - val_accuracy: 0.8499\n",
            "Epoch 209/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.3933 - val_accuracy: 0.8501\n",
            "Epoch 210/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.3964 - val_accuracy: 0.8497\n",
            "Epoch 211/500\n",
            "65/65 [==============================] - 3s 38ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.3992 - val_accuracy: 0.8490\n",
            "Epoch 212/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.3976 - val_accuracy: 0.8497\n",
            "Epoch 213/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 1.4008 - val_accuracy: 0.8492\n",
            "Epoch 214/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 1.4030 - val_accuracy: 0.8495\n",
            "Epoch 215/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.4077 - val_accuracy: 0.8495\n",
            "Epoch 216/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.4047 - val_accuracy: 0.8499\n",
            "Epoch 217/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 1.4162 - val_accuracy: 0.8475\n",
            "Epoch 218/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 1.4096 - val_accuracy: 0.8486\n",
            "Epoch 219/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.4271 - val_accuracy: 0.8468\n",
            "Epoch 220/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 1.4528 - val_accuracy: 0.8374\n",
            "Epoch 221/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 1.3984 - val_accuracy: 0.8419\n",
            "Epoch 222/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 1.3820 - val_accuracy: 0.8475\n",
            "Epoch 223/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 1.3565 - val_accuracy: 0.8466\n",
            "Epoch 224/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 1.3724 - val_accuracy: 0.8519\n",
            "Epoch 225/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.3792 - val_accuracy: 0.8512\n",
            "Epoch 226/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 1.3768 - val_accuracy: 0.8508\n",
            "Epoch 227/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.3856 - val_accuracy: 0.8526\n",
            "Epoch 228/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.3833 - val_accuracy: 0.8519\n",
            "Epoch 229/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.3790 - val_accuracy: 0.8532\n",
            "Epoch 230/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 1.3842 - val_accuracy: 0.8521\n",
            "Epoch 231/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 1.3892 - val_accuracy: 0.8512\n",
            "Epoch 232/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 1.3862 - val_accuracy: 0.8526\n",
            "Epoch 233/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.3822 - val_accuracy: 0.8532\n",
            "Epoch 234/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.3874 - val_accuracy: 0.8526\n",
            "Epoch 235/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.3881 - val_accuracy: 0.8532\n",
            "Epoch 236/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 1.3937 - val_accuracy: 0.8517\n",
            "Epoch 237/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.3935 - val_accuracy: 0.8539\n",
            "Epoch 238/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.3929 - val_accuracy: 0.8530\n",
            "Epoch 239/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.3991 - val_accuracy: 0.8526\n",
            "Epoch 240/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.4004 - val_accuracy: 0.8517\n",
            "Epoch 241/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.3992 - val_accuracy: 0.8532\n",
            "Epoch 242/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.3984 - val_accuracy: 0.8537\n",
            "Epoch 243/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4000 - val_accuracy: 0.8532\n",
            "Epoch 244/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 1.4020 - val_accuracy: 0.8530\n",
            "Epoch 245/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4039 - val_accuracy: 0.8526\n",
            "Epoch 246/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 1.4063 - val_accuracy: 0.8526\n",
            "Epoch 247/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4102 - val_accuracy: 0.8541\n",
            "Epoch 248/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4098 - val_accuracy: 0.8537\n",
            "Epoch 249/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.4108 - val_accuracy: 0.8541\n",
            "Epoch 250/500\n",
            "65/65 [==============================] - 3s 42ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 1.4027 - val_accuracy: 0.8539\n",
            "Epoch 251/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.4162 - val_accuracy: 0.8515\n",
            "Epoch 252/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 1.3814 - val_accuracy: 0.8517\n",
            "Epoch 253/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 1.4201 - val_accuracy: 0.8468\n",
            "Epoch 254/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 1.4046 - val_accuracy: 0.8492\n",
            "Epoch 255/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 1.3987 - val_accuracy: 0.8479\n",
            "Epoch 256/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 1.4049 - val_accuracy: 0.8517\n",
            "Epoch 257/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 1.4140 - val_accuracy: 0.8515\n",
            "Epoch 258/500\n",
            "65/65 [==============================] - 3s 38ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.4198 - val_accuracy: 0.8501\n",
            "Epoch 259/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 1.4168 - val_accuracy: 0.8517\n",
            "Epoch 260/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 1.4209 - val_accuracy: 0.8506\n",
            "Epoch 261/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4218 - val_accuracy: 0.8519\n",
            "Epoch 262/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.4214 - val_accuracy: 0.8503\n",
            "Epoch 263/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.4265 - val_accuracy: 0.8499\n",
            "Epoch 264/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.4149 - val_accuracy: 0.8517\n",
            "Epoch 265/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 1.4259 - val_accuracy: 0.8495\n",
            "Epoch 266/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4203 - val_accuracy: 0.8499\n",
            "Epoch 267/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.4263 - val_accuracy: 0.8510\n",
            "Epoch 268/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.4282 - val_accuracy: 0.8506\n",
            "Epoch 269/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.4270 - val_accuracy: 0.8517\n",
            "Epoch 270/500\n",
            "65/65 [==============================] - 2s 23ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.4309 - val_accuracy: 0.8508\n",
            "Epoch 271/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.4323 - val_accuracy: 0.8517\n",
            "Epoch 272/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.4324 - val_accuracy: 0.8517\n",
            "Epoch 273/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.4369 - val_accuracy: 0.8526\n",
            "Epoch 274/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4363 - val_accuracy: 0.8517\n",
            "Epoch 275/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.4351 - val_accuracy: 0.8519\n",
            "Epoch 276/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4405 - val_accuracy: 0.8519\n",
            "Epoch 277/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.4380 - val_accuracy: 0.8519\n",
            "Epoch 278/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4460 - val_accuracy: 0.8528\n",
            "Epoch 279/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.4476 - val_accuracy: 0.8510\n",
            "Epoch 280/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4463 - val_accuracy: 0.8519\n",
            "Epoch 281/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4439 - val_accuracy: 0.8528\n",
            "Epoch 282/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.4493 - val_accuracy: 0.8519\n",
            "Epoch 283/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 1.4496 - val_accuracy: 0.8519\n",
            "Epoch 284/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4500 - val_accuracy: 0.8526\n",
            "Epoch 285/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4497 - val_accuracy: 0.8523\n",
            "Epoch 286/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4559 - val_accuracy: 0.8519\n",
            "Epoch 287/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4554 - val_accuracy: 0.8506\n",
            "Epoch 288/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4568 - val_accuracy: 0.8519\n",
            "Epoch 289/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4596 - val_accuracy: 0.8512\n",
            "Epoch 290/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4566 - val_accuracy: 0.8526\n",
            "Epoch 291/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4638 - val_accuracy: 0.8526\n",
            "Epoch 292/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 1.4654 - val_accuracy: 0.8521\n",
            "Epoch 293/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.4623 - val_accuracy: 0.8517\n",
            "Epoch 294/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.4661 - val_accuracy: 0.8535\n",
            "Epoch 295/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4687 - val_accuracy: 0.8510\n",
            "Epoch 296/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.4688 - val_accuracy: 0.8510\n",
            "Epoch 297/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4723 - val_accuracy: 0.8512\n",
            "Epoch 298/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.4738 - val_accuracy: 0.8512\n",
            "Epoch 299/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4739 - val_accuracy: 0.8512\n",
            "Epoch 300/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.4742 - val_accuracy: 0.8521\n",
            "Epoch 301/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4702 - val_accuracy: 0.8506\n",
            "Epoch 302/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 1.5281 - val_accuracy: 0.8330\n",
            "Epoch 303/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 1.5181 - val_accuracy: 0.8439\n",
            "Epoch 304/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 1.4713 - val_accuracy: 0.8421\n",
            "Epoch 305/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 1.4762 - val_accuracy: 0.8455\n",
            "Epoch 306/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.4736 - val_accuracy: 0.8459\n",
            "Epoch 307/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.4822 - val_accuracy: 0.8472\n",
            "Epoch 308/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.4839 - val_accuracy: 0.8472\n",
            "Epoch 309/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 1.4830 - val_accuracy: 0.8470\n",
            "Epoch 310/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 1.4853 - val_accuracy: 0.8472\n",
            "Epoch 311/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 1.4813 - val_accuracy: 0.8481\n",
            "Epoch 312/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4888 - val_accuracy: 0.8466\n",
            "Epoch 313/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4895 - val_accuracy: 0.8481\n",
            "Epoch 314/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.4910 - val_accuracy: 0.8479\n",
            "Epoch 315/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.4919 - val_accuracy: 0.8488\n",
            "Epoch 316/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.4931 - val_accuracy: 0.8492\n",
            "Epoch 317/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.4930 - val_accuracy: 0.8479\n",
            "Epoch 318/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4921 - val_accuracy: 0.8499\n",
            "Epoch 319/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.4936 - val_accuracy: 0.8499\n",
            "Epoch 320/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4950 - val_accuracy: 0.8497\n",
            "Epoch 321/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.4959 - val_accuracy: 0.8501\n",
            "Epoch 322/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.4970 - val_accuracy: 0.8492\n",
            "Epoch 323/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.5004 - val_accuracy: 0.8495\n",
            "Epoch 324/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.4976 - val_accuracy: 0.8501\n",
            "Epoch 325/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.4988 - val_accuracy: 0.8501\n",
            "Epoch 326/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.4981 - val_accuracy: 0.8499\n",
            "Epoch 327/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5010 - val_accuracy: 0.8503\n",
            "Epoch 328/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.5004 - val_accuracy: 0.8497\n",
            "Epoch 329/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.5011 - val_accuracy: 0.8510\n",
            "Epoch 330/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5019 - val_accuracy: 0.8499\n",
            "Epoch 331/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.5015 - val_accuracy: 0.8497\n",
            "Epoch 332/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.4997 - val_accuracy: 0.8506\n",
            "Epoch 333/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5035 - val_accuracy: 0.8495\n",
            "Epoch 334/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5027 - val_accuracy: 0.8497\n",
            "Epoch 335/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5029 - val_accuracy: 0.8503\n",
            "Epoch 336/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.5023 - val_accuracy: 0.8499\n",
            "Epoch 337/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5046 - val_accuracy: 0.8508\n",
            "Epoch 338/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5046 - val_accuracy: 0.8503\n",
            "Epoch 339/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5039 - val_accuracy: 0.8497\n",
            "Epoch 340/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5045 - val_accuracy: 0.8501\n",
            "Epoch 341/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5015 - val_accuracy: 0.8512\n",
            "Epoch 342/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5072 - val_accuracy: 0.8510\n",
            "Epoch 343/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5076 - val_accuracy: 0.8503\n",
            "Epoch 344/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.5089 - val_accuracy: 0.8506\n",
            "Epoch 345/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5079 - val_accuracy: 0.8503\n",
            "Epoch 346/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.5085 - val_accuracy: 0.8503\n",
            "Epoch 347/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5072 - val_accuracy: 0.8495\n",
            "Epoch 348/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5081 - val_accuracy: 0.8503\n",
            "Epoch 349/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5078 - val_accuracy: 0.8515\n",
            "Epoch 350/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.5124 - val_accuracy: 0.8508\n",
            "Epoch 351/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5101 - val_accuracy: 0.8503\n",
            "Epoch 352/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5111 - val_accuracy: 0.8497\n",
            "Epoch 353/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5141 - val_accuracy: 0.8499\n",
            "Epoch 354/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5116 - val_accuracy: 0.8492\n",
            "Epoch 355/500\n",
            "65/65 [==============================] - 2s 30ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5125 - val_accuracy: 0.8503\n",
            "Epoch 356/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5153 - val_accuracy: 0.8499\n",
            "Epoch 357/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.5144 - val_accuracy: 0.8510\n",
            "Epoch 358/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5131 - val_accuracy: 0.8510\n",
            "Epoch 359/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5152 - val_accuracy: 0.8501\n",
            "Epoch 360/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5191 - val_accuracy: 0.8506\n",
            "Epoch 361/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5209 - val_accuracy: 0.8506\n",
            "Epoch 362/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5178 - val_accuracy: 0.8512\n",
            "Epoch 363/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5204 - val_accuracy: 0.8510\n",
            "Epoch 364/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.5207 - val_accuracy: 0.8515\n",
            "Epoch 365/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5193 - val_accuracy: 0.8512\n",
            "Epoch 366/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.5231 - val_accuracy: 0.8483\n",
            "Epoch 367/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0483 - accuracy: 0.9863 - val_loss: 1.5716 - val_accuracy: 0.8361\n",
            "Epoch 368/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0539 - accuracy: 0.9839 - val_loss: 1.5323 - val_accuracy: 0.8417\n",
            "Epoch 369/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 1.4756 - val_accuracy: 0.8550\n",
            "Epoch 370/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.4855 - val_accuracy: 0.8535\n",
            "Epoch 371/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.4925 - val_accuracy: 0.8528\n",
            "Epoch 372/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 1.4917 - val_accuracy: 0.8521\n",
            "Epoch 373/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 1.4934 - val_accuracy: 0.8537\n",
            "Epoch 374/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.4928 - val_accuracy: 0.8521\n",
            "Epoch 375/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 1.4972 - val_accuracy: 0.8517\n",
            "Epoch 376/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.4993 - val_accuracy: 0.8528\n",
            "Epoch 377/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.5000 - val_accuracy: 0.8532\n",
            "Epoch 378/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 1.5046 - val_accuracy: 0.8528\n",
            "Epoch 379/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.5066 - val_accuracy: 0.8535\n",
            "Epoch 380/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.5064 - val_accuracy: 0.8528\n",
            "Epoch 381/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5065 - val_accuracy: 0.8523\n",
            "Epoch 382/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5090 - val_accuracy: 0.8526\n",
            "Epoch 383/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.5117 - val_accuracy: 0.8528\n",
            "Epoch 384/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5121 - val_accuracy: 0.8526\n",
            "Epoch 385/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5135 - val_accuracy: 0.8528\n",
            "Epoch 386/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.5166 - val_accuracy: 0.8532\n",
            "Epoch 387/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5144 - val_accuracy: 0.8526\n",
            "Epoch 388/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5179 - val_accuracy: 0.8530\n",
            "Epoch 389/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5187 - val_accuracy: 0.8528\n",
            "Epoch 390/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5177 - val_accuracy: 0.8539\n",
            "Epoch 391/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5238 - val_accuracy: 0.8535\n",
            "Epoch 392/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5215 - val_accuracy: 0.8528\n",
            "Epoch 393/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5223 - val_accuracy: 0.8548\n",
            "Epoch 394/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5218 - val_accuracy: 0.8535\n",
            "Epoch 395/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 1.5227 - val_accuracy: 0.8532\n",
            "Epoch 396/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5239 - val_accuracy: 0.8535\n",
            "Epoch 397/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5228 - val_accuracy: 0.8532\n",
            "Epoch 398/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5301 - val_accuracy: 0.8548\n",
            "Epoch 399/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5285 - val_accuracy: 0.8535\n",
            "Epoch 400/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5274 - val_accuracy: 0.8523\n",
            "Epoch 401/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.5279 - val_accuracy: 0.8532\n",
            "Epoch 402/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5298 - val_accuracy: 0.8530\n",
            "Epoch 403/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5283 - val_accuracy: 0.8535\n",
            "Epoch 404/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5319 - val_accuracy: 0.8523\n",
            "Epoch 405/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5292 - val_accuracy: 0.8535\n",
            "Epoch 406/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5319 - val_accuracy: 0.8528\n",
            "Epoch 407/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 1.5342 - val_accuracy: 0.8535\n",
            "Epoch 408/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5348 - val_accuracy: 0.8535\n",
            "Epoch 409/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5338 - val_accuracy: 0.8539\n",
            "Epoch 410/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5360 - val_accuracy: 0.8537\n",
            "Epoch 411/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5397 - val_accuracy: 0.8530\n",
            "Epoch 412/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5370 - val_accuracy: 0.8532\n",
            "Epoch 413/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5357 - val_accuracy: 0.8537\n",
            "Epoch 414/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5415 - val_accuracy: 0.8528\n",
            "Epoch 415/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5388 - val_accuracy: 0.8541\n",
            "Epoch 416/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5429 - val_accuracy: 0.8543\n",
            "Epoch 417/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5411 - val_accuracy: 0.8539\n",
            "Epoch 418/500\n",
            "65/65 [==============================] - 3s 42ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5434 - val_accuracy: 0.8541\n",
            "Epoch 419/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5454 - val_accuracy: 0.8543\n",
            "Epoch 420/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5466 - val_accuracy: 0.8539\n",
            "Epoch 421/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5463 - val_accuracy: 0.8532\n",
            "Epoch 422/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5494 - val_accuracy: 0.8526\n",
            "Epoch 423/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5472 - val_accuracy: 0.8539\n",
            "Epoch 424/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.5485 - val_accuracy: 0.8539\n",
            "Epoch 425/500\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5492 - val_accuracy: 0.8535\n",
            "Epoch 426/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5511 - val_accuracy: 0.8537\n",
            "Epoch 427/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5533 - val_accuracy: 0.8528\n",
            "Epoch 428/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5550 - val_accuracy: 0.8535\n",
            "Epoch 429/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5549 - val_accuracy: 0.8541\n",
            "Epoch 430/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5563 - val_accuracy: 0.8543\n",
            "Epoch 431/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5544 - val_accuracy: 0.8537\n",
            "Epoch 432/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.5554 - val_accuracy: 0.8541\n",
            "Epoch 433/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5574 - val_accuracy: 0.8543\n",
            "Epoch 434/500\n",
            "65/65 [==============================] - 2s 37ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5567 - val_accuracy: 0.8537\n",
            "Epoch 435/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5591 - val_accuracy: 0.8541\n",
            "Epoch 436/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5609 - val_accuracy: 0.8537\n",
            "Epoch 437/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5670 - val_accuracy: 0.8535\n",
            "Epoch 438/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5626 - val_accuracy: 0.8526\n",
            "Epoch 439/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5643 - val_accuracy: 0.8530\n",
            "Epoch 440/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5684 - val_accuracy: 0.8535\n",
            "Epoch 441/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5740 - val_accuracy: 0.8388\n",
            "Epoch 442/500\n",
            "65/65 [==============================] - 2s 34ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 1.5973 - val_accuracy: 0.8383\n",
            "Epoch 443/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0387 - accuracy: 0.9886 - val_loss: 1.5454 - val_accuracy: 0.8455\n",
            "Epoch 444/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 1.5427 - val_accuracy: 0.8532\n",
            "Epoch 445/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.5266 - val_accuracy: 0.8539\n",
            "Epoch 446/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 1.5248 - val_accuracy: 0.8535\n",
            "Epoch 447/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5272 - val_accuracy: 0.8517\n",
            "Epoch 448/500\n",
            "65/65 [==============================] - 2s 27ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.5335 - val_accuracy: 0.8532\n",
            "Epoch 449/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.5334 - val_accuracy: 0.8526\n",
            "Epoch 450/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.5347 - val_accuracy: 0.8528\n",
            "Epoch 451/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.5349 - val_accuracy: 0.8528\n",
            "Epoch 452/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.5388 - val_accuracy: 0.8528\n",
            "Epoch 453/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.5381 - val_accuracy: 0.8537\n",
            "Epoch 454/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5371 - val_accuracy: 0.8526\n",
            "Epoch 455/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.5405 - val_accuracy: 0.8539\n",
            "Epoch 456/500\n",
            "65/65 [==============================] - 2s 31ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.5433 - val_accuracy: 0.8537\n",
            "Epoch 457/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5467 - val_accuracy: 0.8532\n",
            "Epoch 458/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5462 - val_accuracy: 0.8532\n",
            "Epoch 459/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5479 - val_accuracy: 0.8537\n",
            "Epoch 460/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.5480 - val_accuracy: 0.8537\n",
            "Epoch 461/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 1.5521 - val_accuracy: 0.8541\n",
            "Epoch 462/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5507 - val_accuracy: 0.8541\n",
            "Epoch 463/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5504 - val_accuracy: 0.8541\n",
            "Epoch 464/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5534 - val_accuracy: 0.8543\n",
            "Epoch 465/500\n",
            "65/65 [==============================] - 2s 32ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5532 - val_accuracy: 0.8543\n",
            "Epoch 466/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5548 - val_accuracy: 0.8546\n",
            "Epoch 467/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.5550 - val_accuracy: 0.8541\n",
            "Epoch 468/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5555 - val_accuracy: 0.8555\n",
            "Epoch 469/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 1.5586 - val_accuracy: 0.8541\n",
            "Epoch 470/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.5585 - val_accuracy: 0.8546\n",
            "Epoch 471/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5592 - val_accuracy: 0.8552\n",
            "Epoch 472/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.5592 - val_accuracy: 0.8552\n",
            "Epoch 473/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.5605 - val_accuracy: 0.8548\n",
            "Epoch 474/500\n",
            "65/65 [==============================] - 2s 24ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.5636 - val_accuracy: 0.8548\n",
            "Epoch 475/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.5623 - val_accuracy: 0.8550\n",
            "Epoch 476/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5648 - val_accuracy: 0.8555\n",
            "Epoch 477/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5628 - val_accuracy: 0.8550\n",
            "Epoch 478/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5681 - val_accuracy: 0.8557\n",
            "Epoch 479/500\n",
            "65/65 [==============================] - 3s 39ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.5671 - val_accuracy: 0.8557\n",
            "Epoch 480/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5691 - val_accuracy: 0.8552\n",
            "Epoch 481/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5672 - val_accuracy: 0.8559\n",
            "Epoch 482/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5710 - val_accuracy: 0.8552\n",
            "Epoch 483/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5734 - val_accuracy: 0.8543\n",
            "Epoch 484/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5708 - val_accuracy: 0.8559\n",
            "Epoch 485/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.5740 - val_accuracy: 0.8557\n",
            "Epoch 486/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.5772 - val_accuracy: 0.8552\n",
            "Epoch 487/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5761 - val_accuracy: 0.8552\n",
            "Epoch 488/500\n",
            "65/65 [==============================] - 2s 38ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.5774 - val_accuracy: 0.8541\n",
            "Epoch 489/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5784 - val_accuracy: 0.8555\n",
            "Epoch 490/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.5761 - val_accuracy: 0.8559\n",
            "Epoch 491/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5774 - val_accuracy: 0.8555\n",
            "Epoch 492/500\n",
            "65/65 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 1.5800 - val_accuracy: 0.8555\n",
            "Epoch 493/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.5798 - val_accuracy: 0.8561\n",
            "Epoch 494/500\n",
            "65/65 [==============================] - 2s 33ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5786 - val_accuracy: 0.8557\n",
            "Epoch 495/500\n",
            "65/65 [==============================] - 3s 41ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5812 - val_accuracy: 0.8563\n",
            "Epoch 496/500\n",
            "65/65 [==============================] - 2s 29ms/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 1.5791 - val_accuracy: 0.8557\n",
            "Epoch 497/500\n",
            "65/65 [==============================] - 2s 28ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.5835 - val_accuracy: 0.8548\n",
            "Epoch 498/500\n",
            "65/65 [==============================] - 3s 40ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5851 - val_accuracy: 0.8550\n",
            "Epoch 499/500\n",
            "65/65 [==============================] - 2s 35ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.5839 - val_accuracy: 0.8548\n",
            "Epoch 500/500\n",
            "65/65 [==============================] - 2s 25ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.5850 - val_accuracy: 0.8543\n",
            "Training accuracy 99.88%\n",
            "\n",
            "Training completed!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# training the model\n",
        "\n",
        "EPOCHS = 500\n",
        "bi_lstm_all = []\n",
        "bi_lstm_acc = []\n",
        "batch_sizes = [8, 16]\n",
        "for batch_size in batch_sizes:\n",
        "    print(f'\\nCurrent batch size: {batch_size}')\n",
        "    model = build_bi_lstm()\n",
        "    bi_lstm = model[0]\n",
        "    bi_lstm.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = bi_lstm.fit([encoder_input_data, decoder_input_data], decoder_output_data, epochs=EPOCHS, batch_size=batch_size, validation_split=0.1)\n",
        "    bi_lstm.save_weights(f'./bi_lstm_{batch_size}.h5')\n",
        "    acc = history.history.get('accuracy')\n",
        "    bi_lstm_all.append(acc)\n",
        "    print(f'Training accuracy {\"{:.2%}\".format(acc[-1])}')\n",
        "    bi_lstm_acc.append(acc[-1])\n",
        "\n",
        "print('\\nTraining completed!\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "FuGIhpezEXZ6",
        "outputId": "b7425fd2-bb15-477c-ee48-6298b6d05454"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Akurasi\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Simpan gambar\n",
        "plt.savefig('training_plot.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan visualisasi sebagai file PNG\n",
        "plt.savefig('visualisasi loss acc.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5o5jdrtgO1O9",
        "outputId": "c99ef37c-9761-4ed1-bce9-c64c470b747e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4IieHBK6CCNT",
        "outputId": "159fc122-3d6b-4f0e-f712-7dd1b71e6164"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#accuracy\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Set Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Set Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxPlc0g1GKmV"
      },
      "source": [
        "###Create Inference Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlUOGVBCtL_G"
      },
      "outputs": [],
      "source": [
        "def make_inference_models():\n",
        "  # load biderectional lstm model with the best batch size\n",
        "    bi_lstm, enc_inputs, enc_states, dec_inputs, dec_embedding, dec_lstm, dec_dense = build_bi_lstm()\n",
        "    batch_size = batch_sizes[np.argmax(bi_lstm_acc)]\n",
        "    bi_lstm.load_weights(f'./bi_lstm_{batch_size}.h5')\n",
        "    # decoder model\n",
        "    dec_state_input_h = Input(shape=(HIDDEN_DIM * 2,))\n",
        "    dec_state_input_c = Input(shape=(HIDDEN_DIM * 2,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    dec_outputs, state_h, state_c = dec_lstm(dec_embedding,\n",
        "                                    initial_state=dec_states_inputs)\n",
        "    dec_states = [state_h, state_c]\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "    # encoder model\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "    return enc_model, dec_model\n",
        "\n",
        "def str_to_tokens(sentence: str):\n",
        "    # convert input string to lowercase,\n",
        "    # then split it by whitespaces\n",
        "    words = sentence.lower().split()\n",
        "    # and then convert to a sequence\n",
        "    # of integers padded with zeros\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != '':\n",
        "            tokens_list.append(result)\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen=maxlen_questions,\n",
        "                         padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvHGoNQEtSTJ",
        "outputId": "b21c22d6-a5be-4f95-a8f6-3ef1e745adf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: siapa kamu?\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Chatbot: sama dipublikasikan dipublikasikan mahasiswa memiliki malam memiliki 144 tidak memiliki nilai e dan memiliki surat penunjukkan pembimbing yang masih aktif sudah melakukan bimbingan minimal 5 kali setelah seminar proposal sudah menghadiri seminar hasil mahasiswa lain minimal 5 kali menyerahkan laporan tugas akhir sesuai kriteria dengan maksimal plagiarisme 35 serta menyerahkan laporan kepada dosen pembimbing dan dosen penguji yang dibuktikan melalui tanda tangan pada form pendaftaran seminar hasil tugas akhir \n",
            "You: kamu siapa?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: saya adalah chatbot informasi seminar fst \n",
            "You: mengapa kamu diciptakan?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: saya adalah program komputer yang akan membantu menjawab rasa penasaran anda seputar layanan administasi di fakultas sains dan teknologi \n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "# create encoder/decoder models\n",
        "encoder_model, decoder_model = make_inference_models()\n",
        "# interact with the chatbot\n",
        "while True:\n",
        "    # encode the input sequence into state vectors\n",
        "    input_text = input('You: ')\n",
        "    if input_text == 'exit':\n",
        "        break\n",
        "    states_values = encoder_model.predict(str_to_tokens(input_text))\n",
        "    # start with a target sequence of size 1 - word 'start'\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition:\n",
        "        # feed the state vectors and 1-word target sequence\n",
        "        # to the decoder to produce predictions for the next word\n",
        "        dec_outputs, h, c = decoder_model.predict([empty_target_seq]+states_values)\n",
        "        # sample the next word using these predictions\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        # append the sampled word to the target sequence\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'end':\n",
        "                    decoded_translation += f'{word} '\n",
        "                sampled_word = word\n",
        "        # repeat until we generate the end-of-sequence word 'end'\n",
        "        # or we hit the length of answer limit\n",
        "        if sampled_word == 'end' \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > maxlen_answers:\n",
        "            stop_condition = True\n",
        "        # prepare next iteration\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "    print('Chatbot: '+decoded_translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7q5wcHsk-YU",
        "outputId": "4bdc8e60-8284-4489-8603-39af29058395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Simpan encoder model ke dalam file terpisah\n",
        "encoder_model.save('encoder_model.h5')\n",
        "\n",
        "# Simpan decoder model ke dalam file terpisah\n",
        "decoder_model.save('decoder_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNAEVJJFG_Yy"
      },
      "source": [
        "###Save Model to h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtrlClebHDWO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Menyimpan model ke file .h5\n",
        "bi_lstm.save('model_chatbot.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ1uIfYmc5Cb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Simpan objek tokenizer menggunakan pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
        "    pickle.dump(tokenizer, tokenizer_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3JhOqx8H-eI"
      },
      "source": [
        "###Evaluasi BLEU Scor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExkPLGYICI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e75ebd4-285b-43bc-de4a-34088a9b869d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Apa yang harus saya lakukan untuk mengetahui status terkini dari surat yang diajukan?\n",
            "Expected Answer: Salah satu cara adalah dengan menggunakan menu Tracking Surat di website seminar-fst.uin-suska.ac.id. Selain itu, pastikan email yang telah diinputkan sebelumnya pada proses pengajuan untuk menerima pemberitahuan.\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: salah satu cara adalah dengan menggunakan menu tracking surat di website seminar fst uin suska ac id selain itu pastikan email yang telah diinputkan sebelumnya pada prose pengajuan untuk menerima pemberitahuan\n",
            "BLEU Score: 0.6471840946505604\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Interaksi dengan chatbot\n",
        "while True:\n",
        "    # encode the input sequence into state vectors\n",
        "    input_text = input('You: ')\n",
        "    if input_text == 'exit':\n",
        "        break\n",
        "    reference_answer = input(\"Expected Answer: \")  # Tambahkan input dari pengguna sebagai jawaban referensi\n",
        "    reference_answer = clean_text(reference_answer)  # Bersihkan teks jawaban referensi\n",
        "    reference_answer = '<START> ' + reference_answer + ' <END>'  # Tambahkan token <START> dan <END>\n",
        "\n",
        "    states_values = encoder_model.predict(str_to_tokens(input_text))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition:\n",
        "        dec_outputs, h, c = decoder_model.predict([empty_target_seq]+states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'end':\n",
        "                    decoded_translation += f'{word} '\n",
        "                sampled_word = word\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    decoded_translation = decoded_translation.strip()  # Hapus spasi ekstra di awal dan akhir kalimat\n",
        "    bleu_score = sentence_bleu([reference_answer.split()], decoded_translation.split())\n",
        "    print('Chatbot: ' + decoded_translation)\n",
        "    print('BLEU Score:', bleu_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUy2Bi6q2D_X"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Membersihkan pertanyaan dan jawaban dari dataset\n",
        "cleaned_questions, cleaned_answers = get_clean_q_and_a(all_conversations)\n",
        "\n",
        "# Memprediksi jawaban dari pertanyaan-pertanyaan dalam dataset\n",
        "predicted_answers = []\n",
        "for question in cleaned_questions:\n",
        "    states_values = encoder_model.predict(str_to_tokens(question))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition:\n",
        "        dec_outputs, h, c = decoder_model.predict([empty_target_seq] + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != 'end':\n",
        "                    decoded_translation += f'{word} '\n",
        "                sampled_word = word\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "    predicted_answers.append(decoded_translation.strip().split())\n",
        "\n",
        "# Hitung BLEU score untuk seluruh dataset\n",
        "reference_answers = [[answer.split()] for answer in cleaned_answers]\n",
        "bleu_score = corpus_bleu(reference_answers, predicted_answers)\n",
        "\n",
        "print('BLEU Score for the Entire Dataset:', bleu_score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}